{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import spacy\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "import numpy as np\n",
    "import nltk\n",
    "import plac\n",
    "import random\n",
    "from pathlib import Path\n",
    "from spacy.util import minibatch, compounding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatise_text(text):\n",
    "    tweet_nlp = nlp(text)\n",
    "    l = [token.lemma_ for token in tweet_nlp ]\n",
    "    return (\" \".join(l)).replace(\" \\n\",\"\")\n",
    "\n",
    "def stem_text(text):\n",
    "    words = word_tokenize(text)\n",
    "    l = [stemmer.stem(token) for token in words]\n",
    "    return \" \".join(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"C:/Users/Benco/Anaconda3/Lib/site-packages/fr_core_news_sm/fr_core_news_sm-2.2.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('french')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FAQ_disney = pd.DataFrame(pd.read_pickle(\"C:/Users/Benco/Documents/chatBot_disney/faq.pkl\"))\n",
    "FAQ_disney[\"target\"] = 1\n",
    "FAQ_disney[\"question\"] = FAQ_disney[\"question\"].apply(lambda text : text.replace(\"\\xa0\" , \"\"))\n",
    "FAQ_disney[\"reponse\"] = FAQ_disney[\"reponse\"].apply(lambda text : text.replace(\"\\xa0\" , \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = requests.get(\"https://www.nike.com/fr/fr_fr/c/kids/how-to-buy-kids-shoes-faq\").text\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "questions = soup.findAll(\"span\",\n",
    "                      {\"class\": \"nike-cq-subtitle-line-1 nike-cq-title-line nike-cq-line1 nsg-text--dark-grey nike-cq-font22px nike-cq-spacing08px nsg-font-family--platform\"}\n",
    "                        )\n",
    "questions = [quest.text.replace(\"\\xa0\" , \"\") for quest in questions]\n",
    "responses = [div.find(\"p\").text for div in soup.findAll(\"div\", { \"data-component-container\" : \"true\" , \"class\"  : \"nike-cq-text\"})]\n",
    "responses = list(map(lambda resp : resp.replace(\"\\n\" , \"\").strip().replace(\"  \",\"\").replace(\"\\xa0\",\"\") , responses))\n",
    "FAQ_nike = pd.DataFrame([{\"question\" : quest , \"reponse\" : rep} for quest , rep in zip(questions , responses)])\n",
    "FAQ_nike[\"target\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_free = requests.get(\"https://mobile.free.fr/assistance/163.html\").text\n",
    "soup_free = BeautifulSoup(html_free, 'lxml')\n",
    "question_free = [q.text.replace(\"\\xa0\" , \"\") for q in soup_free.select(\"li.clicMe > strong\")]\n",
    "rep_free = [r.text.strip().replace(\"\\xa0\",\"\").replace(\"\\n\",\"\").replace(\"\\t\",\"\") for r in soup_free.select(\"li.hideMe\")]\n",
    "FAQ_free = pd.DataFrame([{\"question\" : quest , \"reponse\" : rep} for quest , rep in zip(question_free , rep_free)])\n",
    "FAQ_free[\"target\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = (FAQ_disney.append(FAQ_nike)).append(FAQ_free)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"lemmas_rep\"] = train[\"reponse\"].apply(lemmatise_text)\n",
    "train[\"lemmas_quest\"] = train[\"question\"].apply(lemmatise_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"stem_rep\"] = train[\"reponse\"].apply(stem_text)\n",
    "train[\"stem_quest\"] = train[\"question\"].apply(stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"train.csv\" , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comment postul pour un travail à disneyland paris ?\n",
      "je possed actuel un passeport annuel classic , fantasy ou dream et je souhait l ’ échang contr un nouveau pass annuel , existe-t-il un prix au prorat de jour rest ?\n",
      "avec le billet privileg , l ’ offre billet amis est-el amen à disparaîtr ?\n",
      "avec un pass annuel infinity , puis-j fair bénéfici de l'espac privilégi pour la parad et le show disney illumin à me invit billet privileg , billet amis , autr détenteur de pass annuel ou autr ticket ?\n",
      "combien de mois sont offert pour le parrainag de 3 filleul effectu et valid avant le 28 mar 2017 et sur quel pass annuel ?\n",
      "comment déclar un chang d'adress ou autr situat ?\n",
      "comment fêt un anniversair à disneyland paris ?\n",
      "comment le fastpass disneyland paris peut-il m'évit de fair la queu ?\n",
      "comment me rendr aux parc disney depuis mon hôtel ?\n",
      "comment me rendr aux parc disney depuis mon hôtel ?\n",
      "comment puis-j me procur de ticket fastpassl jour de ma visit aux parc et diminu le temp d ’ attent dan certain attract à succes ?\n",
      "est-ce possibl de prendr un rep avec de personnag disney ?\n",
      "est-ce que je vais recevoir une offre de renouvel lorsqu mon pass annuel arriv à expir ?\n",
      "est-il possibl de recevoir un pass annuel direct chez soi ?\n",
      "existe-t-il de visit guid de parc disney ?\n",
      "existe-t-il de visit guid de parc disney ?\n",
      "existe-t-il un servic objet trouv dan le parc disney ?\n",
      "j'ai une question mais je ne trouv pas la répons dan cet rubriqu , que puis-j fair ?\n",
      "je suis handicap . est-ce que je bénéfic d'un acces spécial aux attract et spectacl ?\n",
      "je suis handicap . quel attract me conviennent ?\n",
      "je vais prendr le train pour me rendr à disneyland paris , y a-t-il une gar à proxim de parc disney ?\n",
      "j ’ ai bénéfici de mois gratuit de l ’ offre de parrainag et je souhait l ’ échang contr un nouveau pass annuel , quel prix dois-j pai ?\n",
      "le prix avec un pai compt ou mensuel est-il le mêm ?\n",
      "le prix du parking est-il inclus dan le billet d'entr ?\n",
      "le accompagn d'un pass annuel magic plus ou infinity peuvent-il égal profit de l'acces dédi à l ’ entré de parc ?\n",
      "notr budget est serr . y a-t-il de restaur moin cher dan le parc disney ?\n",
      "où chang de devis à disneyland paris ?\n",
      "où puis-j chang ou nourr mon beb ou réchauff de bib ?\n",
      "où puis-j me gar à disneyland paris ?\n",
      "où puis-j me rendr si je me bless ou si j'ai besoin de soin médical ?\n",
      "où puis-j me rendr si mon enfant se bless ou a besoin de soin médical ?\n",
      "où puis-j retir de l'argent dan le parc ?\n",
      "où puis-j voir le personnag disney à disneyland paris ?\n",
      "où se trouv disneyland paris par rapport aux aéroport parisien ?\n",
      "où trouv de descript et photos de hôtel disney ?\n",
      "où trouv de inform sur le limit de taill et d'âg pour le attract de disneyland paris ?\n",
      "où trouv de inform sur le éven de saison et le offre spécial ?\n",
      "où trouv un plan de disneyland paris et de parc disney ?\n",
      "l ’ utilis de perch télescop , utilis not pour le self , est-el autoris dan le parc à them de disneyland paris ?\n",
      "y a-t-il un cod vestimentair à disneyland paris ?\n",
      "je possed actuel un passeport annuel classic , fantasy ou dream , suis-j oblig ( e ) de le chang pour un nouveau pass annuel ?\n",
      "le jour de restrict s ’ appliquent-t-il si l ’ on séjourn dan un hôtel disney ?\n",
      "puis-j aller dan le parc et hôtel disney avec mon chien ou mon chat ?\n",
      "puis-j apport de la nourritur dan le parc disney ?\n",
      "puis-j fum dan le parc disney ?\n",
      "puis-j me rendr à disneyland paris en transport en commun ?\n",
      "puis-j sort d'un parc disney et reven plus tard le mêm jour ?\n",
      "qu'est-c que disney villag et que peut-on y fair ?\n",
      "qu'est-c que l'express check-out ?\n",
      "qu'est-c que le fastpass disneyland paris et comment fonctionne-t-il ?\n",
      "qu ' y a-t-il à fair à disneyland paris ?\n",
      "que dois-j fair en cas de pert ou de vol de mon pass annuel ?\n",
      "que fair si mon enfant se perd dan un parc disney ?\n",
      "que sont le moment de mag en plus ?\n",
      "quel est le meilleur moment pour visit disneyland paris ?\n",
      "quel est le meilleur moyen de se déplac au sein de disneyland paris ?\n",
      "quel est le meilleur moyen de se déplac au sein de disneyland paris ?\n",
      "quel attract conviennent à mon enfant ?\n",
      "quel attract seront en cour de rénov ou de remis en état au cour de mon séjour ?\n",
      "quel sont le activ possibl à disneyland paris pour le vacanc ?\n",
      "quel sont le activ possibl à disneyland paris pour le vacanc ?\n",
      "quel sont le coordon de disneyland paris ?\n",
      "quel sont le heur d'ouvertur de parc disney ?\n",
      "quel sont le mesur de sécur mis en plac à disneyland paris ?\n",
      "quel hôtel sont situ à proxim de parc disney ?\n",
      "quel servic sont disponibl pour le enfant et beb dan le hôtel disney ?\n",
      "quel sont le avantag du pass annuel ?\n",
      "est-il possibl d ’ achet un photopass+ annuel pour le détenteur d ’ un passeport annuel de l ’ ancien gamm en cour de valid ?\n",
      "quel sont le horair d'ouvertur du bureau pass annuel ?\n",
      "quel typ de restaur trouv t-on dan le parc disney ?\n",
      "si je fais de achat dan une boutiqu disney , dois-j le port tout la journ ?\n",
      "y a-t-il de chos à fair s'il pleut lor de mon séjour à disneyland paris ?\n",
      "y a-t-il de pousset dan le parc disney ?\n",
      "y a-t-il de servic spécial et de attract pour le beb et enfant en bas âge ?\n",
      "y a-t-il un acces wif à disneyland paris ?\n",
      "à quel heur sont l'enregistr et le départ dan le hôtel disney ?\n",
      "quel sont le meilleur chaussur pour l'écol ?\n",
      "à quel fréquenc dois-j achet de nouvel chaussur ?\n",
      "peut-on port de chaussur nik san chausset ?\n",
      "pourquoi la chaussur de mon enfant glisse-t-el au niveau du talon ?\n",
      "pourquoi le chaussur de mon enfant grincent-el parfois ?\n",
      "comment savoir si le chaussur de mon enfant sont trop grand ?\n",
      "la marqu nik propose-t-el de chaussur san lacet ?\n",
      "combien de temp durent le chaussur à crampon ?\n",
      "mon enfant peut-il port de chaussur à crampon destin à d'autr sport , comm le football américain ou le baseball , pour le match de football ?\n",
      "qu'est-c que le col dynamic fit ?\n",
      "comment mettr une chaussur à crampon avec un col ?\n",
      "pourquoi la soupless est-el import ?\n",
      "quel sont le meilleur chaussur pour le running ?\n",
      "le forf à 2 € est-il accessibl à tous ?\n",
      "lor de mon inscript chez fre , j ’ ai demand à conserv mon numéro de mobil actuel ( portabl ) , dois-j résili mon abon chez mon ancien oper ?\n",
      "combien dois-j pai de frais de résili si je quitt mon oper actuel alor que je suis encor engag ?\n",
      "mon téléphon est verrouill ( `` simlock '' ) chez mon oper actuel . que dois-j fair avant de m ’ abon chez fre ?\n",
      "je souhait command un téléphon chez fre , comment fair ?\n",
      "pourrai-j utilis mon mobil pour du partag de connexion ( permettr grâc à mon mobil un acces à internet à un ordin , une tablet ou un autr téléphon ) ?\n",
      "puis-j profit du réseau freewif ?\n",
      "le réseau mobil de fre est-il compatibl 3g , 3g+ et 4g ?\n",
      "comment fair pour profit de la 4g ? est-ce gratuit ?\n",
      "je dispos d ’ un blackberry , devrai-j pai l ’ option blackberry pour profit de servic internet associ ?\n",
      "j ’ ai un iphon . vais-j recevoir une cart sim au format adapt ?\n",
      "lor de mon inscript , j ’ ai oubli de chois la portabl de mon numéro . puis-j l ’ obten final ?\n",
      "comment abon le autr membr du foi en forf mobil ?\n",
      "si je suis abon freebox , puis-j bénéfici d ’ un `` forf fre '' à 15,99 € par mois et souscrir auss le `` forf 2€ '' factur à 0 € par mois ?\n",
      "l ’ offre préférentiel destin aux freenaut adsl n ’ est-el donc valabl qu ’ une fois ?\n",
      "comment profit d ’ un deuxiem ( ou troisiem , ou quatriem ) `` forf fre '' à 15,99 € par mois ?\n",
      "comment puis-j vérifi que ma souscript a été enregistr ?\n",
      "j ’ ai reçu l ’ email de confirm de souscript . quand vais-j recevoir ma cart sim ?\n",
      "quel est le coût de la cart sim ?\n",
      "j ’ ai perdu ma cart sim . que fair ?\n",
      "je n ’ ai reçu ni mail de confirm ni identifi pour me connect à mon espac abon . que dois-j fair ?\n",
      "que comprend la premi factur mobil ?\n"
     ]
    }
   ],
   "source": [
    "for tr in train[\"stem_quest\"]:\n",
    "    print(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def localisation(texte , words , label):\n",
    "    pos = texte.index(words)\n",
    "    return (pos , pos + len(words) - 1 , label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL = \"Disney\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"disneyland\" , \"pass\" , \"billet\" , \"disney\" , \"pass\" , \"adress\" , \"anniversair\",\n",
    "        \"pass\" , \"parc\" , \"parc\" , 'attract' , 'personnag' , \"pass\" , 'pass' , \"disney\" , \"disney\",\n",
    "        \"disney\" , \"répons\" , \"spectacl\" , \"attract\" , \"disney\" , 'pass' , \"compt\" , \"entr\" , 'parc',\n",
    "        \"restaur\" , \"disneyland\" , \"beb\" , \"disneyland\" ,\" soin\" ,'enfant',\"parc\" , \"personnag\", \"disneyland\",\n",
    "         \"hôtel\" , \"âg\" , \"éven\" , \"plan\" , \"parc\" , \"disneyland\" , \"classic , fantasy ou dream\" , \"hôtel\",\n",
    "         \"hôtel\" , \"parc\" , \"parc\" , \"disneyland\" , \"parc\" , \"villag\" ,\"check-out\" , \"pass\" , \"disneyland\",\n",
    "         \"pass\" , 'enfant' , \"moment\" ,\"moment\" , \"déplac\" , \"déplac\" , \"attract\" , \"attract\" , \"activ\" , \"activ\",\n",
    "         \"coordon\" , \"ouvertur\" , \"sécur\" , \"proxim\" , \"beb\" , \"avantag\" , \"passeport\" , \"bureau\" , \"restaur\",\n",
    "         \"boutiqu\" , \"séjour\" , \"pousset\" , 'bas âge' , \"acces wif\" , \"départ\"\n",
    "        ]\n",
    "\n",
    "TRAIN_DATA = [(train[\"stem_quest\"].iloc[i] , \n",
    "           {\"entities\" : [ localisation(train[\"stem_quest\"].iloc[i] , words[i] , LABEL) ]}\n",
    "              )\n",
    "              for i in range(len(words))]\n",
    "TRAIN_DATA += [(train[\"stem_quest\"].iloc[i], {\"entities\" :  []}) for i in range(76 , 111)]\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"C:/Users/Benco/Documents/chatBot_disney\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function plac_core.annotations.<locals>.annotate(f)>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plac.annotations(\n",
    "    model=(\"Model name. Defaults to blank 'en' model.\", \"option\", \"m\", str),\n",
    "    new_model_name=(\"New model name for model meta.\", \"option\", \"nm\", str),\n",
    "    output_dir=(\"Optional output directory\", \"option\", \"o\", pathlib.Path),\n",
    "    n_iter=(\"Number of training iterations\", \"option\", \"n\", int),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(model=None, output_dir=None, n_iter=100):\n",
    "    random.seed(0)\n",
    "    \"\"\"Load the model, set up the pipeline and train the entity recognizer.\"\"\"\n",
    "    if model is not None:\n",
    "        nlp = spacy.load(model)  # load existing spaCy model\n",
    "        print(\"Loaded model '%s'\" % model)\n",
    "    else:\n",
    "        nlp = spacy.blank(\"fr\")  # create blank Language class\n",
    "        print(\"Created blank 'fr' model\")\n",
    "\n",
    "    # create the built-in pipeline components and add them to the pipeline\n",
    "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "    if \"ner\" not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe(\"ner\")\n",
    "        nlp.add_pipe(ner)\n",
    "    # otherwise, get it so we can add labels\n",
    "    else:\n",
    "        ner = nlp.get_pipe(\"ner\")\n",
    "        \n",
    "    ner.add_label(\"Disney\")\n",
    "    ##mess nothing\n",
    "    ner.add_label(\"VEGETABLE\")\n",
    "    if model is None:\n",
    "        optimizer = nlp.begin_training()\n",
    "    else:\n",
    "        optimize = nlp.resume_training()\n",
    "    move_names = list(ner.move_names)\n",
    "    #get names of other pipes to disable them during training\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if(pipe != \"ner\")]\n",
    "    while nlp.pipe_names == [\"tagger\" , \"parser\" , \"ner\"]: #only train ner\n",
    "        nlp.disable_pipes(*other_pipes)\n",
    "        sizes = compounding(1.0 , 4.0 , 1.001)\n",
    "        #batch up\n",
    "        for itn in range(n_iter):\n",
    "            random.shuffle(TRAIN_DATA)\n",
    "            batches = minibatch(TRAIN_DATA , size = sizes)\n",
    "            losses = {}\n",
    "            for batch in batches:\n",
    "                texts , annotations = zip(*batch)\n",
    "                nlp.update(texts , annotations , sgd = optimize , drop = 0.35 , losses = losses)\n",
    "            print(\"Losses\" , losses)\n",
    "    for text, _ in TRAIN_DATA:\n",
    "        doc = nlp(text)\n",
    "        print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n",
    "        print(\"Tokens\", [(t.text, t.ent_type_, t.ent_iob) for t in doc])\n",
    "    if output_dir is not None:\n",
    "        output_dir = Path(output_dir)\n",
    "        if not output_dir.exists():\n",
    "            output_dir.mkdir()\n",
    "        nlp.to_disk(output_dir)\n",
    "        print(\"Saved model to\", output_dir)\n",
    "    print(\"Loading from\", output_dir)\n",
    "    nlp2 = spacy.load(output_dir)\n",
    "    for text, _ in TRAIN_DATA:\n",
    "        doc = nlp2(text)\n",
    "        print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n",
    "        print(\"Tokens\", [(t.text, t.ent_type_, t.ent_iob) for t in doc])\n",
    "    test_text = stem_text('et on achète le pain ou ?')\n",
    "    doc = nlp(test_text)\n",
    "    print(\"Entities in '%s'\" % test_text)\n",
    "    for ent in doc.ents:\n",
    "        print(ent.label , ent.text)\n",
    "        \n",
    "    if output_dir is not None:\n",
    "        output_dir = Path(output_dir)\n",
    "    if not output_dir.exists():\n",
    "        output_dir.mkdir()\n",
    "        nlp.meta[\"name\"] = \"new_model_name\"\n",
    "        nlp.to_disk(output_dir)\n",
    "        print(\"Saved model to\" , output_dir)\n",
    "    #test the saved model\n",
    "    print(\"Loading from\" , output_dir)\n",
    "    nlp2 = spacy.load(output_dir)\n",
    "    #check the classes have loaded back consis\n",
    "    assert nlp2.get_pipe(\"ner\").move_names == move_names\n",
    "    doc2 = nlp2(test_text)\n",
    "    for ent in doc2.ents:\n",
    "        print(ent.label , ent.text)\n",
    "#save model to output directory\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model 'C:/Users/Benco/Anaconda3/Lib/site-packages/fr_core_news_sm/fr_core_news_sm-2.2.5'\n",
      "Losses {'ner': 1095.7731546511832}\n",
      "Losses {'ner': 934.9953700358476}\n",
      "Losses {'ner': 890.5119107285877}\n",
      "Losses {'ner': 906.7485730136284}\n",
      "Losses {'ner': 852.9999429074815}\n",
      "Losses {'ner': 858.7525098717881}\n",
      "Losses {'ner': 790.9843814342134}\n",
      "Losses {'ner': 857.3191888498768}\n",
      "Losses {'ner': 853.7036814013227}\n",
      "Losses {'ner': 848.5764848834042}\n",
      "Losses {'ner': 861.407534239197}\n",
      "Losses {'ner': 815.2668902937176}\n",
      "Losses {'ner': 849.9819708114192}\n",
      "Losses {'ner': 854.0952256819346}\n",
      "Losses {'ner': 822.3861806461355}\n",
      "Losses {'ner': 824.7419423013926}\n",
      "Losses {'ner': 861.1788164612954}\n",
      "Losses {'ner': 843.9031866565347}\n",
      "Losses {'ner': 810.8673251956934}\n",
      "Losses {'ner': 846.9992763027549}\n",
      "Losses {'ner': 807.692088027994}\n",
      "Losses {'ner': 877.6222118735313}\n",
      "Losses {'ner': 800.4432575106621}\n",
      "Losses {'ner': 758.1764730215073}\n",
      "Losses {'ner': 807.8273440003395}\n",
      "Losses {'ner': 808.810177760286}\n",
      "Losses {'ner': 779.8187552243471}\n",
      "Losses {'ner': 762.9298154264688}\n",
      "Losses {'ner': 803.6420248150826}\n",
      "Losses {'ner': 787.6038005799055}\n",
      "Losses {'ner': 821.1215584959427}\n",
      "Losses {'ner': 812.1425350010395}\n",
      "Losses {'ner': 790.4288074932992}\n",
      "Losses {'ner': 804.9946113824844}\n",
      "Losses {'ner': 813.1895218193531}\n",
      "Losses {'ner': 811.7553223278501}\n",
      "Losses {'ner': 756.8209001421928}\n",
      "Losses {'ner': 834.3173283934593}\n",
      "Losses {'ner': 828.7782269120216}\n",
      "Losses {'ner': 824.2601406276226}\n",
      "Losses {'ner': 807.1050620675087}\n",
      "Losses {'ner': 812.6379368901253}\n",
      "Losses {'ner': 833.3139917552471}\n",
      "Losses {'ner': 781.3001901730895}\n",
      "Losses {'ner': 804.4754482507706}\n",
      "Losses {'ner': 790.4336283023877}\n",
      "Losses {'ner': 804.6352996239439}\n",
      "Losses {'ner': 778.1423320136964}\n",
      "Losses {'ner': 783.4501809179783}\n",
      "Losses {'ner': 843.6778267920017}\n",
      "Losses {'ner': 805.99971217243}\n",
      "Losses {'ner': 814.603826135397}\n",
      "Losses {'ner': 793.5001241266727}\n",
      "Losses {'ner': 813.2850715070963}\n",
      "Losses {'ner': 825.0368386696209}\n",
      "Losses {'ner': 765.4348995536566}\n",
      "Losses {'ner': 830.54427292943}\n",
      "Losses {'ner': 797.9863425791264}\n",
      "Losses {'ner': 794.029692094773}\n",
      "Losses {'ner': 814.6332532763481}\n",
      "Losses {'ner': 800.3783233165741}\n",
      "Losses {'ner': 809.9972229003906}\n",
      "Losses {'ner': 824.2988722026348}\n",
      "Losses {'ner': 829.4102625846863}\n",
      "Losses {'ner': 800.2986169933574}\n",
      "Losses {'ner': 821.7359894216061}\n",
      "Losses {'ner': 776.2489117234945}\n",
      "Losses {'ner': 797.1593566826559}\n",
      "Losses {'ner': 821.0390758275316}\n",
      "Losses {'ner': 818.1675387769938}\n",
      "Losses {'ner': 799.6299130747284}\n",
      "Losses {'ner': 833.3059463202953}\n",
      "Losses {'ner': 808.0860585570335}\n",
      "Losses {'ner': 822.7642222642899}\n",
      "Losses {'ner': 768.3270715475082}\n",
      "Losses {'ner': 806.5481018722057}\n",
      "Losses {'ner': 805.4129768013954}\n",
      "Losses {'ner': 786.3599852323532}\n",
      "Losses {'ner': 811.4370547235012}\n",
      "Losses {'ner': 780.0244416594505}\n",
      "Losses {'ner': 815.5654636695981}\n",
      "Losses {'ner': 846.5402129888535}\n",
      "Losses {'ner': 790.6787104383111}\n",
      "Losses {'ner': 802.965267278254}\n",
      "Losses {'ner': 834.4616681486368}\n",
      "Losses {'ner': 819.8070819973946}\n",
      "Losses {'ner': 824.6224739943864}\n",
      "Losses {'ner': 788.3297912541748}\n",
      "Losses {'ner': 807.4073850901186}\n",
      "Losses {'ner': 801.7035585343838}\n",
      "Losses {'ner': 825.0156686007977}\n",
      "Losses {'ner': 811.7221848517656}\n",
      "Losses {'ner': 812.1047811806202}\n",
      "Losses {'ner': 812.6535789533518}\n",
      "Losses {'ner': 795.1982271746965}\n",
      "Losses {'ner': 817.7125705182552}\n",
      "Losses {'ner': 803.4475912153721}\n",
      "Losses {'ner': 804.9295323193073}\n",
      "Losses {'ner': 841.253137677908}\n",
      "Losses {'ner': 821.4836350977421}\n",
      "Entities []\n",
      "Tokens [('puis', '', 2), ('-', '', 2), ('j', '', 2), ('sort', '', 2), (\"d'\", '', 2), ('un', '', 2), ('parc', '', 2), ('disney', '', 2), ('et', '', 2), ('reven', '', 2), ('plus', '', 2), ('tard', '', 2), ('le', '', 2), ('mêm', '', 2), ('jour', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('y', '', 2), ('a', '', 2), ('-t', '', 2), ('-il', '', 2), ('de', '', 2), ('servic', '', 2), ('spécial', '', 2), ('et', '', 2), ('de', '', 2), ('attract', '', 2), ('pour', '', 2), ('le', '', 2), ('beb', '', 2), ('et', '', 2), ('enfant', '', 2), ('en', '', 2), ('bas', '', 2), ('âge', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('pourrai', '', 2), ('-', '', 2), ('j', '', 2), ('utilis', '', 2), ('mon', '', 2), ('mobil', '', 2), ('pour', '', 2), ('du', '', 2), ('partag', '', 2), ('de', '', 2), ('connexion', '', 2), ('(', '', 2), ('permettr', '', 2), ('grâc', '', 2), ('à', '', 2), ('mon', '', 2), ('mobil', '', 2), ('un', '', 2), ('acces', '', 2), ('à', '', 2), ('internet', '', 2), ('à', '', 2), ('un', '', 2), ('ordin', '', 2), (',', '', 2), ('une', '', 2), ('tablet', '', 2), ('ou', '', 2), ('un', '', 2), ('autr', '', 2), ('téléphon', '', 2), (')', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('existe', '', 2), ('-', '', 2), ('t', '', 2), ('-', '', 2), ('il', '', 2), ('un', '', 2), ('servic', '', 2), ('objet', '', 2), ('trouv', '', 2), ('dan', '', 2), ('le', '', 2), ('parc', '', 2), ('disney', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('comment', '', 2), ('me', '', 2), ('rendr', '', 2), ('aux', '', 2), ('parc', '', 2), ('disney', '', 2), ('depuis', '', 2), ('mon', '', 2), ('hôtel', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('où', '', 2), ('chang', '', 2), ('de', '', 2), ('devis', '', 2), ('à', '', 2), ('disneyland', '', 2), ('paris', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('combien', '', 2), ('de', '', 2), ('temp', '', 2), ('durent', '', 2), ('le', '', 2), ('chaussur', '', 2), ('à', '', 2), ('crampon', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('comment', '', 2), ('postul', '', 2), ('pour', '', 2), ('un', '', 2), ('travail', '', 2), ('à', '', 2), ('disneyland', '', 2), ('paris', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('comment', '', 2), ('puis', '', 2), ('-', '', 2), ('j', '', 2), ('me', '', 2), ('procur', '', 2), ('de', '', 2), ('ticket', '', 2), ('fastpassl', '', 2), ('jour', '', 2), ('de', '', 2), ('ma', '', 2), ('visit', '', 2), ('aux', '', 2), ('parc', '', 2), ('et', '', 2), ('diminu', '', 2), ('le', '', 2), ('temp', '', 2), ('d', '', 2), ('’', '', 2), ('attent', '', 2), ('dan', '', 2), ('certain', '', 2), ('attract', '', 2), ('à', '', 2), ('succes', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('quel', '', 2), ('sont', '', 2), ('le', '', 2), ('horair', '', 2), (\"d'\", '', 2), ('ouvertur', '', 2), ('du', '', 2), ('bureau', '', 2), ('pass', '', 2), ('annuel', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('avec', '', 2), ('le', '', 2), ('billet', '', 2), ('privileg', '', 2), (',', '', 2), ('l', '', 2), ('’', '', 2), ('offre', '', 2), ('billet', '', 2), ('amis', '', 2), ('est-el', '', 2), ('amen', '', 2), ('à', '', 2), ('disparaîtr', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('notr', '', 2), ('budget', '', 2), ('est', '', 2), ('serr', '', 2), ('.', '', 2), ('y', '', 2), ('a', '', 2), ('-t', '', 2), ('-il', '', 2), ('de', '', 2), ('restaur', '', 2), ('moin', '', 2), ('cher', '', 2), ('dan', '', 2), ('le', '', 2), ('parc', '', 2), ('disney', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('que', '', 2), ('fair', '', 2), ('si', '', 2), ('mon', '', 2), ('enfant', '', 2), ('se', '', 2), ('perd', '', 2), ('dan', '', 2), ('un', '', 2), ('parc', '', 2), ('disney', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('est-il', '', 2), ('possibl', '', 2), ('de', '', 2), ('recevoir', '', 2), ('un', '', 2), ('pass', '', 2), ('annuel', '', 2), ('direct', '', 2), ('chez', '', 2), ('soi', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('combien', '', 2), ('de', '', 2), ('mois', '', 2), ('sont', '', 2), ('offert', '', 2), ('pour', '', 2), ('le', '', 2), ('parrainag', '', 2), ('de', '', 2), ('3', '', 2), ('filleul', '', 2), ('effectu', '', 2), ('et', '', 2), ('valid', '', 2), ('avant', '', 2), ('le', '', 2), ('28', '', 2), ('mar', '', 2), ('2017', '', 2), ('et', '', 2), ('sur', '', 2), ('quel', '', 2), ('pass', '', 2), ('annuel', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('le', '', 2), ('accompagn', '', 2), (\"d'\", '', 2), ('un', '', 2), ('pass', '', 2), ('annuel', '', 2), ('magic', '', 2), ('plus', '', 2), ('ou', '', 2), ('infinity', '', 2), ('peuvent', '', 2), ('-', '', 2), ('il', '', 2), ('égal', '', 2), ('profit', '', 2), ('de', '', 2), (\"l'\", '', 2), ('acces', '', 2), ('dédi', '', 2), ('à', '', 2), ('l', '', 2), ('’', '', 2), ('entré', '', 2), ('de', '', 2), ('parc', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('pourquoi', '', 2), ('la', '', 2), ('chaussur', '', 2), ('de', '', 2), ('mon', '', 2), ('enfant', '', 2), ('glisse', '', 2), ('-', '', 2), ('t', '', 2), ('-', '', 2), ('el', '', 2), ('au', '', 2), ('niveau', '', 2), ('du', '', 2), ('talon', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('où', '', 2), ('puis', '', 2), ('-', '', 2), ('j', '', 2), ('retir', '', 2), ('de', '', 2), (\"l'\", '', 2), ('argent', '', 2), ('dan', '', 2), ('le', '', 2), ('parc', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('à', '', 2), ('quel', '', 2), ('fréquenc', '', 2), ('dois', '', 2), ('-', '', 2), ('j', '', 2), ('achet', '', 2), ('de', '', 2), ('nouvel', '', 2), ('chaussur', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('j', '', 2), ('’', '', 2), ('ai', '', 2), ('un', '', 2), ('iphon', '', 2), ('.', '', 2), ('vais', '', 2), ('-', '', 2), ('j', '', 2), ('recevoir', '', 2), ('une', '', 2), ('cart', '', 2), ('sim', '', 2), ('au', '', 2), ('format', '', 2), ('adapt', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('comment', '', 2), ('mettr', '', 2), ('une', '', 2), ('chaussur', '', 2), ('à', '', 2), ('crampon', '', 2), ('avec', '', 2), ('un', '', 2), ('col', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('si', '', 2), ('je', '', 2), ('fais', '', 2), ('de', '', 2), ('achat', '', 2), ('dan', '', 2), ('une', '', 2), ('boutiqu', '', 2), ('disney', '', 2), (',', '', 2), ('dois', '', 2), ('-', '', 2), ('j', '', 2), ('le', '', 2), ('port', '', 2), ('tout', '', 2), ('la', '', 2), ('journ', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('où', '', 2), ('trouv', '', 2), ('de', '', 2), ('descript', '', 2), ('et', '', 2), ('photos', '', 2), ('de', '', 2), ('hôtel', '', 2), ('disney', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('est', '', 2), ('-ce', '', 2), ('que', '', 2), ('je', '', 2), ('vais', '', 2), ('recevoir', '', 2), ('une', '', 2), ('offre', '', 2), ('de', '', 2), ('renouvel', '', 2), ('lorsqu', '', 2), ('mon', '', 2), ('pass', '', 2), ('annuel', '', 2), ('arriv', '', 2), ('à', '', 2), ('expir', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('existe', '', 2), ('-', '', 2), ('t', '', 2), ('-', '', 2), ('il', '', 2), ('de', '', 2), ('visit', '', 2), ('guid', '', 2), ('de', '', 2), ('parc', '', 2), ('disney', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('comment', '', 2), ('me', '', 2), ('rendr', '', 2), ('aux', '', 2), ('parc', '', 2), ('disney', '', 2), ('depuis', '', 2), ('mon', '', 2), ('hôtel', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('quel', '', 2), ('hôtel', '', 2), ('sont', '', 2), ('situ', '', 2), ('à', '', 2), ('proxim', '', 2), ('de', '', 2), ('parc', '', 2), ('disney', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('où', '', 2), ('trouv', '', 2), ('de', '', 2), ('inform', '', 2), ('sur', '', 2), ('le', '', 2), ('éven', '', 2), ('de', '', 2), ('saison', '', 2), ('et', '', 2), ('le', '', 2), ('offre', '', 2), ('spécial', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('je', '', 2), ('dispos', '', 2), ('d', '', 2), ('’', '', 2), ('un', '', 2), ('blackberry', '', 2), (',', '', 2), ('devrai', '', 2), ('-', '', 2), ('j', '', 2), ('pai', '', 2), ('l', '', 2), ('’', '', 2), ('option', '', 2), ('blackberry', '', 2), ('pour', '', 2), ('profit', '', 2), ('de', '', 2), ('servic', '', 2), ('internet', '', 2), ('associ', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('quel', '', 2), ('sont', '', 2), ('le', '', 2), ('activ', '', 2), ('possibl', '', 2), ('à', '', 2), ('disneyland', '', 2), ('paris', '', 2), ('pour', '', 2), ('le', '', 2), ('vacanc', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('à', '', 2), ('quel', '', 2), ('heur', '', 2), ('sont', '', 2), (\"l'\", '', 2), ('enregistr', '', 2), ('et', '', 2), ('le', '', 2), ('départ', '', 2), ('dan', '', 2), ('le', '', 2), ('hôtel', '', 2), ('disney', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [(\"qu'\", '', 2), ('est', '', 2), ('-', '', 2), ('c', '', 2), ('que', '', 2), ('le', '', 2), ('fastpass', '', 2), ('disneyland', '', 2), ('paris', '', 2), ('et', '', 2), ('comment', '', 2), ('fonctionne', '', 2), ('-', '', 2), ('t', '', 2), ('-', '', 2), ('il', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('où', '', 2), ('puis', '', 2), ('-', '', 2), ('j', '', 2), ('me', '', 2), ('rendr', '', 2), ('si', '', 2), ('je', '', 2), ('me', '', 2), ('bless', '', 2), ('ou', '', 2), ('si', '', 2), (\"j'\", '', 2), ('ai', '', 2), ('besoin', '', 2), ('de', '', 2), ('soin', '', 2), ('médical', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [(\"qu'\", '', 2), ('est', '', 2), ('-', '', 2), ('c', '', 2), ('que', '', 2), (\"l'\", '', 2), ('express', '', 2), ('check', '', 2), ('-', '', 2), ('out', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [(\"qu'\", '', 2), ('est', '', 2), ('-', '', 2), ('c', '', 2), ('que', '', 2), ('le', '', 2), ('col', '', 2), ('dynamic', '', 2), ('fit', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('quel', '', 2), ('servic', '', 2), ('sont', '', 2), ('disponibl', '', 2), ('pour', '', 2), ('le', '', 2), ('enfant', '', 2), ('et', '', 2), ('beb', '', 2), ('dan', '', 2), ('le', '', 2), ('hôtel', '', 2), ('disney', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('puis', '', 2), ('-', '', 2), ('j', '', 2), ('apport', '', 2), ('de', '', 2), ('la', '', 2), ('nourritur', '', 2), ('dan', '', 2), ('le', '', 2), ('parc', '', 2), ('disney', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('quel', '', 2), ('typ', '', 2), ('de', '', 2), ('restaur', '', 2), ('trouv', '', 2), ('t', '', 2), ('-', '', 2), ('on', '', 2), ('dan', '', 2), ('le', '', 2), ('parc', '', 2), ('disney', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('le', '', 2), ('forf', '', 2), ('à', '', 2), ('2', '', 2), ('€', '', 2), ('est-il', '', 2), ('accessibl', '', 2), ('à', '', 2), ('tous', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('que', '', 2), ('sont', '', 2), ('le', '', 2), ('moment', '', 2), ('de', '', 2), ('mag', '', 2), ('en', '', 2), ('plus', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('quel', '', 2), ('sont', '', 2), ('le', '', 2), ('meilleur', '', 2), ('chaussur', '', 2), ('pour', '', 2), ('le', '', 2), ('running', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('quel', '', 2), ('attract', '', 2), ('seront', '', 2), ('en', '', 2), ('cour', '', 2), ('de', '', 2), ('rénov', '', 2), ('ou', '', 2), ('de', '', 2), ('remis', '', 2), ('en', '', 2), ('état', '', 2), ('au', '', 2), ('cour', '', 2), ('de', '', 2), ('mon', '', 2), ('séjour', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('pourquoi', '', 2), ('le', '', 2), ('chaussur', '', 2), ('de', '', 2), ('mon', '', 2), ('enfant', '', 2), ('grincent', '', 2), ('-', '', 2), ('el', '', 2), ('parfois', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('j', '', 2), ('’', '', 2), ('ai', '', 2), ('bénéfici', '', 2), ('de', '', 2), ('mois', '', 2), ('gratuit', '', 2), ('de', '', 2), ('l', '', 2), ('’', '', 2), ('offre', '', 2), ('de', '', 2), ('parrainag', '', 2), ('et', '', 2), ('je', '', 2), ('souhait', '', 2), ('l', '', 2), ('’', '', 2), ('échang', '', 2), ('contr', '', 2), ('un', '', 2), ('nouveau', '', 2), ('pass', '', 2), ('annuel', '', 2), (',', '', 2), ('quel', '', 2), ('prix', '', 2), ('dois', '', 2), ('-', '', 2), ('j', '', 2), ('pai', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('où', '', 2), ('se', '', 2), ('trouv', '', 2), ('disneyland', '', 2), ('paris', '', 2), ('par', '', 2), ('rapport', '', 2), ('aux', '', 2), ('aéroport', '', 2), ('parisien', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('quel', '', 2), ('est', '', 2), ('le', '', 2), ('meilleur', '', 2), ('moment', '', 2), ('pour', '', 2), ('visit', '', 2), ('disneyland', '', 2), ('paris', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('où', '', 2), ('puis', '', 2), ('-', '', 2), ('j', '', 2), ('me', '', 2), ('rendr', '', 2), ('si', '', 2), ('mon', '', 2), ('enfant', '', 2), ('se', '', 2), ('bless', '', 2), ('ou', '', 2), ('a', '', 2), ('besoin', '', 2), ('de', '', 2), ('soin', '', 2), ('médical', '', 2), ('?', '', 2)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities []\n",
      "Tokens [('comment', '', 2), ('puis', '', 2), ('-', '', 2), ('j', '', 2), ('vérifi', '', 2), ('que', '', 2), ('ma', '', 2), ('souscript', '', 2), ('a', '', 2), ('été', '', 2), ('enregistr', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('où', '', 2), ('puis', '', 2), ('-', '', 2), ('j', '', 2), ('chang', '', 2), ('ou', '', 2), ('nourr', '', 2), ('mon', '', 2), ('beb', '', 2), ('ou', '', 2), ('réchauff', '', 2), ('de', '', 2), ('bib', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('le', '', 2), ('prix', '', 2), ('avec', '', 2), ('un', '', 2), ('pai', '', 2), ('compt', '', 2), ('ou', '', 2), ('mensuel', '', 2), ('est-il', '', 2), ('le', '', 2), ('mêm', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('combien', '', 2), ('dois', '', 2), ('-', '', 2), ('j', '', 2), ('pai', '', 2), ('de', '', 2), ('frais', '', 2), ('de', '', 2), ('résili', '', 2), ('si', '', 2), ('je', '', 2), ('quitt', '', 2), ('mon', '', 2), ('oper', '', 2), ('actuel', '', 2), ('alor', '', 2), ('que', '', 2), ('je', '', 2), ('suis', '', 2), ('encor', '', 2), ('engag', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('je', '', 2), ('souhait', '', 2), ('command', '', 2), ('un', '', 2), ('téléphon', '', 2), ('chez', '', 2), ('fre', '', 2), (',', '', 2), ('comment', '', 2), ('fair', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('comment', '', 2), ('profit', '', 2), ('d', '', 2), ('’', '', 2), ('un', '', 2), ('deuxiem', '', 2), ('(', '', 2), ('ou', '', 2), ('troisiem', '', 2), (',', '', 2), ('ou', '', 2), ('quatriem', '', 2), (')', '', 2), ('`', '', 2), ('`', '', 2), ('forf', '', 2), ('fre', '', 2), (\"''\", '', 2), ('à', '', 2), ('15,99', '', 2), ('€', '', 2), ('par', '', 2), ('mois', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [(\"j'\", '', 2), ('ai', '', 2), ('une', '', 2), ('question', '', 2), ('mais', '', 2), ('je', '', 2), ('ne', '', 2), ('trouv', '', 2), ('pas', '', 2), ('la', '', 2), ('répons', '', 2), ('dan', '', 2), ('cet', '', 2), ('rubriqu', '', 2), (',', '', 2), ('que', '', 2), ('puis', '', 2), ('-', '', 2), ('j', '', 2), ('fair', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('mon', '', 2), ('enfant', '', 2), ('peut', '', 2), ('-', '', 2), ('il', '', 2), ('port', '', 2), ('de', '', 2), ('chaussur', '', 2), ('à', '', 2), ('crampon', '', 2), ('destin', '', 2), ('à', '', 2), (\"d'\", '', 2), ('autr', '', 2), ('sport', '', 2), (',', '', 2), ('comm', '', 2), ('le', '', 2), ('football', '', 2), ('américain', '', 2), ('ou', '', 2), ('le', '', 2), ('baseball', '', 2), (',', '', 2), ('pour', '', 2), ('le', '', 2), ('match', '', 2), ('de', '', 2), ('football', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('je', '', 2), ('possed', '', 2), ('actuel', '', 2), ('un', '', 2), ('passeport', '', 2), ('annuel', '', 2), ('classic', '', 2), (',', '', 2), ('fantasy', '', 2), ('ou', '', 2), ('dream', '', 2), (',', '', 2), ('suis', '', 2), ('-', '', 2), ('j', '', 2), ('oblig', '', 2), ('(', '', 2), ('e', '', 2), (')', '', 2), ('de', '', 2), ('le', '', 2), ('chang', '', 2), ('pour', '', 2), ('un', '', 2), ('nouveau', '', 2), ('pass', '', 2), ('annuel', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [(\"qu'\", '', 2), ('est', '', 2), ('-', '', 2), ('c', '', 2), ('que', '', 2), ('disney', '', 2), ('villag', '', 2), ('et', '', 2), ('que', '', 2), ('peut', '', 2), ('-', '', 2), ('on', '', 2), ('y', '', 2), ('fair', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('le', '', 2), ('réseau', '', 2), ('mobil', '', 2), ('de', '', 2), ('fre', '', 2), ('est-il', '', 2), ('compatibl', '', 2), ('3', '', 2), ('g', '', 2), (',', '', 2), ('3g+', '', 2), ('et', '', 2), ('4', '', 2), ('g', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('où', '', 2), ('puis', '', 2), ('-', '', 2), ('j', '', 2), ('voir', '', 2), ('le', '', 2), ('personnag', '', 2), ('disney', '', 2), ('à', '', 2), ('disneyland', '', 2), ('paris', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('où', '', 2), ('trouv', '', 2), ('de', '', 2), ('inform', '', 2), ('sur', '', 2), ('le', '', 2), ('limit', '', 2), ('de', '', 2), ('taill', '', 2), ('et', '', 2), (\"d'\", '', 2), ('âg', '', 2), ('pour', '', 2), ('le', '', 2), ('attract', '', 2), ('de', '', 2), ('disneyland', '', 2), ('paris', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('comment', '', 2), ('abon', '', 2), ('le', '', 2), ('autr', '', 2), ('membr', '', 2), ('du', '', 2), ('foi', '', 2), ('en', '', 2), ('forf', '', 2), ('mobil', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('où', '', 2), ('puis', '', 2), ('-', '', 2), ('j', '', 2), ('me', '', 2), ('gar', '', 2), ('à', '', 2), ('disneyland', '', 2), ('paris', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('comment', '', 2), ('fêt', '', 2), ('un', '', 2), ('anniversair', '', 2), ('à', '', 2), ('disneyland', '', 2), ('paris', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('je', '', 2), ('suis', '', 2), ('handicap', '', 2), ('.', '', 2), ('quel', '', 2), ('attract', '', 2), ('me', '', 2), ('conviennent', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('l', '', 2), ('’', '', 2), ('offre', '', 2), ('préférentiel', '', 2), ('destin', '', 2), ('aux', '', 2), ('freenaut', '', 2), ('adsl', '', 2), ('n', '', 2), ('’', '', 2), ('est-el', '', 2), ('donc', '', 2), ('valabl', '', 2), ('qu', '', 2), ('’', '', 2), ('une', '', 2), ('fois', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('où', '', 2), ('trouv', '', 2), ('un', '', 2), ('plan', '', 2), ('de', '', 2), ('disneyland', '', 2), ('paris', '', 2), ('et', '', 2), ('de', '', 2), ('parc', '', 2), ('disney', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('quel', '', 2), ('sont', '', 2), ('le', '', 2), ('mesur', '', 2), ('de', '', 2), ('sécur', '', 2), ('mis', '', 2), ('en', '', 2), ('plac', '', 2), ('à', '', 2), ('disneyland', '', 2), ('paris', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('je', '', 2), ('possed', '', 2), ('actuel', '', 2), ('un', '', 2), ('passeport', '', 2), ('annuel', '', 2), ('classic', '', 2), (',', '', 2), ('fantasy', '', 2), ('ou', '', 2), ('dream', '', 2), ('et', '', 2), ('je', '', 2), ('souhait', '', 2), ('l', '', 2), ('’', '', 2), ('échang', '', 2), ('contr', '', 2), ('un', '', 2), ('nouveau', '', 2), ('pass', '', 2), ('annuel', '', 2), (',', '', 2), ('existe', '', 2), ('-', '', 2), ('t', '', 2), ('-', '', 2), ('il', '', 2), ('un', '', 2), ('prix', '', 2), ('au', '', 2), ('prorat', '', 2), ('de', '', 2), ('jour', '', 2), ('rest', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('je', '', 2), ('vais', '', 2), ('prendr', '', 2), ('le', '', 2), ('train', '', 2), ('pour', '', 2), ('me', '', 2), ('rendr', '', 2), ('à', '', 2), ('disneyland', '', 2), ('paris', '', 2), (',', '', 2), ('y', '', 2), ('a', '', 2), ('-t', '', 2), ('-il', '', 2), ('une', '', 2), ('gar', '', 2), ('à', '', 2), ('proxim', '', 2), ('de', '', 2), ('parc', '', 2), ('disney', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('qu', '', 2), (\"'\", '', 2), ('y', '', 2), ('a', '', 2), ('-t', '', 2), ('-il', '', 2), ('à', '', 2), ('fair', '', 2), ('à', '', 2), ('disneyland', '', 2), ('paris', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('quel', '', 2), ('sont', '', 2), ('le', '', 2), ('activ', '', 2), ('possibl', '', 2), ('à', '', 2), ('disneyland', '', 2), ('paris', '', 2), ('pour', '', 2), ('le', '', 2), ('vacanc', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('quel', '', 2), ('sont', '', 2), ('le', '', 2), ('avantag', '', 2), ('du', '', 2), ('pass', '', 2), ('annuel', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('j', '', 2), ('’', '', 2), ('ai', '', 2), ('perdu', '', 2), ('ma', '', 2), ('cart', '', 2), ('sim', '', 2), ('.', '', 2), ('que', '', 2), ('fair', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('puis', '', 2), ('-', '', 2), ('j', '', 2), ('profit', '', 2), ('du', '', 2), ('réseau', '', 2), ('freewif', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('comment', '', 2), ('fair', '', 2), ('pour', '', 2), ('profit', '', 2), ('de', '', 2), ('la', '', 2), ('4', '', 2), ('g', '', 2), ('?', '', 2), ('est', '', 2), ('-ce', '', 2), ('gratuit', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('y', '', 2), ('a', '', 2), ('-t', '', 2), ('-il', '', 2), ('de', '', 2), ('chos', '', 2), ('à', '', 2), ('fair', '', 2), (\"s'\", '', 2), ('il', '', 2), ('pleut', '', 2), ('lor', '', 2), ('de', '', 2), ('mon', '', 2), ('séjour', '', 2), ('à', '', 2), ('disneyland', '', 2), ('paris', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('est-il', '', 2), ('possibl', '', 2), ('d', '', 2), ('’', '', 2), ('achet', '', 2), ('un', '', 2), ('photopass+', '', 2), ('annuel', '', 2), ('pour', '', 2), ('le', '', 2), ('détenteur', '', 2), ('d', '', 2), ('’', '', 2), ('un', '', 2), ('passeport', '', 2), ('annuel', '', 2), ('de', '', 2), ('l', '', 2), ('’', '', 2), ('ancien', '', 2), ('gamm', '', 2), ('en', '', 2), ('cour', '', 2), ('de', '', 2), ('valid', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('le', '', 2), ('jour', '', 2), ('de', '', 2), ('restrict', '', 2), ('s', '', 2), ('’', '', 2), ('appliquent', '', 2), ('-', '', 2), ('t', '', 2), ('-', '', 2), ('il', '', 2), ('si', '', 2), ('l', '', 2), ('’', '', 2), ('on', '', 2), ('séjourn', '', 2), ('dan', '', 2), ('un', '', 2), ('hôtel', '', 2), ('disney', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('avec', '', 2), ('un', '', 2), ('pass', '', 2), ('annuel', '', 2), ('infinity', '', 2), (',', '', 2), ('puis', '', 2), ('-', '', 2), ('j', '', 2), ('fair', '', 2), ('bénéfici', '', 2), ('de', '', 2), (\"l'\", '', 2), ('espac', '', 2), ('privilégi', '', 2), ('pour', '', 2), ('la', '', 2), ('parad', '', 2), ('et', '', 2), ('le', '', 2), ('show', '', 2), ('disney', '', 2), ('illumin', '', 2), ('à', '', 2), ('me', '', 2), ('invit', '', 2), ('billet', '', 2), ('privileg', '', 2), (',', '', 2), ('billet', '', 2), ('amis', '', 2), (',', '', 2), ('autr', '', 2), ('détenteur', '', 2), ('de', '', 2), ('pass', '', 2), ('annuel', '', 2), ('ou', '', 2), ('autr', '', 2), ('ticket', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('je', '', 2), ('n', '', 2), ('’', '', 2), ('ai', '', 2), ('reçu', '', 2), ('ni', '', 2), ('mail', '', 2), ('de', '', 2), ('confirm', '', 2), ('ni', '', 2), ('identifi', '', 2), ('pour', '', 2), ('me', '', 2), ('connect', '', 2), ('à', '', 2), ('mon', '', 2), ('espac', '', 2), ('abon', '', 2), ('.', '', 2), ('que', '', 2), ('dois', '', 2), ('-', '', 2), ('j', '', 2), ('fair', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('puis', '', 2), ('-', '', 2), ('j', '', 2), ('aller', '', 2), ('dan', '', 2), ('le', '', 2), ('parc', '', 2), ('et', '', 2), ('hôtel', '', 2), ('disney', '', 2), ('avec', '', 2), ('mon', '', 2), ('chien', '', 2), ('ou', '', 2), ('mon', '', 2), ('chat', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('puis', '', 2), ('-', '', 2), ('j', '', 2), ('me', '', 2), ('rendr', '', 2), ('à', '', 2), ('disneyland', '', 2), ('paris', '', 2), ('en', '', 2), ('transport', '', 2), ('en', '', 2), ('commun', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('lor', '', 2), ('de', '', 2), ('mon', '', 2), ('inscript', '', 2), (',', '', 2), ('j', '', 2), ('’', '', 2), ('ai', '', 2), ('oubli', '', 2), ('de', '', 2), ('chois', '', 2), ('la', '', 2), ('portabl', '', 2), ('de', '', 2), ('mon', '', 2), ('numéro', '', 2), ('.', '', 2), ('puis', '', 2), ('-', '', 2), ('j', '', 2), ('l', '', 2), ('’', '', 2), ('obten', '', 2), ('final', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('le', '', 2), ('prix', '', 2), ('du', '', 2), ('parking', '', 2), ('est-il', '', 2), ('inclus', '', 2), ('dan', '', 2), ('le', '', 2), ('billet', '', 2), (\"d'\", '', 2), ('entr', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('la', '', 2), ('marqu', '', 2), ('nik', '', 2), ('propose', '', 2), ('-', '', 2), ('t', '', 2), ('-', '', 2), ('el', '', 2), ('de', '', 2), ('chaussur', '', 2), ('san', '', 2), ('lacet', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('quel', '', 2), ('sont', '', 2), ('le', '', 2), ('coordon', '', 2), ('de', '', 2), ('disneyland', '', 2), ('paris', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('quel', '', 2), ('sont', '', 2), ('le', '', 2), ('meilleur', '', 2), ('chaussur', '', 2), ('pour', '', 2), (\"l'\", '', 2), ('écol', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('y', '', 2), ('a', '', 2), ('-t', '', 2), ('-il', '', 2), ('un', '', 2), ('cod', '', 2), ('vestimentair', '', 2), ('à', '', 2), ('disneyland', '', 2), ('paris', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('est', '', 2), ('-ce', '', 2), ('possibl', '', 2), ('de', '', 2), ('prendr', '', 2), ('un', '', 2), ('rep', '', 2), ('avec', '', 2), ('de', '', 2), ('personnag', '', 2), ('disney', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('existe', '', 2), ('-', '', 2), ('t', '', 2), ('-', '', 2), ('il', '', 2), ('de', '', 2), ('visit', '', 2), ('guid', '', 2), ('de', '', 2), ('parc', '', 2), ('disney', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('puis', '', 2), ('-', '', 2), ('j', '', 2), ('fum', '', 2), ('dan', '', 2), ('le', '', 2), ('parc', '', 2), ('disney', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('mon', '', 2), ('téléphon', '', 2), ('est', '', 2), ('verrouill', '', 2), ('(', '', 2), ('`', '', 2), ('`', '', 2), ('simlock', '', 2), (\"''\", '', 2), (')', '', 2), ('chez', '', 2), ('mon', '', 2), ('oper', '', 2), ('actuel', '', 2), ('.', '', 2), ('que', '', 2), ('dois', '', 2), ('-', '', 2), ('j', '', 2), ('fair', '', 2), ('avant', '', 2), ('de', '', 2), ('m', '', 2), ('’', '', 2), ('abon', '', 2), ('chez', '', 2), ('fre', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('y', '', 2), ('a', '', 2), ('-t', '', 2), ('-il', '', 2), ('de', '', 2), ('pousset', '', 2), ('dan', '', 2), ('le', '', 2), ('parc', '', 2), ('disney', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('que', '', 2), ('dois', '', 2), ('-', '', 2), ('j', '', 2), ('fair', '', 2), ('en', '', 2), ('cas', '', 2), ('de', '', 2), ('pert', '', 2), ('ou', '', 2), ('de', '', 2), ('vol', '', 2), ('de', '', 2), ('mon', '', 2), ('pass', '', 2), ('annuel', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('que', '', 2), ('comprend', '', 2), ('la', '', 2), ('premi', '', 2), ('factur', '', 2), ('mobil', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('quel', '', 2), ('sont', '', 2), ('le', '', 2), ('heur', '', 2), (\"d'\", '', 2), ('ouvertur', '', 2), ('de', '', 2), ('parc', '', 2), ('disney', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('quel', '', 2), ('attract', '', 2), ('conviennent', '', 2), ('à', '', 2), ('mon', '', 2), ('enfant', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('si', '', 2), ('je', '', 2), ('suis', '', 2), ('abon', '', 2), ('freebox', '', 2), (',', '', 2), ('puis', '', 2), ('-', '', 2), ('j', '', 2), ('bénéfici', '', 2), ('d', '', 2), ('’', '', 2), ('un', '', 2), ('`', '', 2), ('`', '', 2), ('forf', '', 2), ('fre', '', 2), (\"''\", '', 2), ('à', '', 2), ('15,99', '', 2), ('€', '', 2), ('par', '', 2), ('mois', '', 2), ('et', '', 2), ('souscrir', '', 2), ('auss', '', 2), ('le', '', 2), ('`', '', 2), ('`', '', 2), ('forf', '', 2), ('2', '', 2), ('€', '', 2), (\"''\", '', 2), ('factur', '', 2), ('à', '', 2), ('0', '', 2), ('€', '', 2), ('par', '', 2), ('mois', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('quel', '', 2), ('est', '', 2), ('le', '', 2), ('coût', '', 2), ('de', '', 2), ('la', '', 2), ('cart', '', 2), ('sim', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('y', '', 2), ('a', '', 2), ('-t', '', 2), ('-il', '', 2), ('un', '', 2), ('acces', '', 2), ('wif', '', 2), ('à', '', 2), ('disneyland', '', 2), ('paris', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('comment', '', 2), ('le', '', 2), ('fastpass', '', 2), ('disneyland', '', 2), ('paris', '', 2), ('peut', '', 2), ('-', '', 2), ('il', '', 2), (\"m'\", '', 2), ('évit', '', 2), ('de', '', 2), ('fair', '', 2), ('la', '', 2), ('queu', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('quel', '', 2), ('est', '', 2), ('le', '', 2), ('meilleur', '', 2), ('moyen', '', 2), ('de', '', 2), ('se', '', 2), ('déplac', '', 2), ('au', '', 2), ('sein', '', 2), ('de', '', 2), ('disneyland', '', 2), ('paris', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('quel', '', 2), ('est', '', 2), ('le', '', 2), ('meilleur', '', 2), ('moyen', '', 2), ('de', '', 2), ('se', '', 2), ('déplac', '', 2), ('au', '', 2), ('sein', '', 2), ('de', '', 2), ('disneyland', '', 2), ('paris', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('j', '', 2), ('’', '', 2), ('ai', '', 2), ('reçu', '', 2), ('l', '', 2), ('’', '', 2), ('email', '', 2), ('de', '', 2), ('confirm', '', 2), ('de', '', 2), ('souscript', '', 2), ('.', '', 2), ('quand', '', 2), ('vais', '', 2), ('-', '', 2), ('j', '', 2), ('recevoir', '', 2), ('ma', '', 2), ('cart', '', 2), ('sim', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('pourquoi', '', 2), ('la', '', 2), ('soupless', '', 2), ('est-el', '', 2), ('import', '', 2), ('?', '', 2)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities []\n",
      "Tokens [('comment', '', 2), ('déclar', '', 2), ('un', '', 2), ('chang', '', 2), (\"d'\", '', 2), ('adress', '', 2), ('ou', '', 2), ('autr', '', 2), ('situat', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('lor', '', 2), ('de', '', 2), ('mon', '', 2), ('inscript', '', 2), ('chez', '', 2), ('fre', '', 2), (',', '', 2), ('j', '', 2), ('’', '', 2), ('ai', '', 2), ('demand', '', 2), ('à', '', 2), ('conserv', '', 2), ('mon', '', 2), ('numéro', '', 2), ('de', '', 2), ('mobil', '', 2), ('actuel', '', 2), ('(', '', 2), ('portabl', '', 2), (')', '', 2), (',', '', 2), ('dois', '', 2), ('-', '', 2), ('j', '', 2), ('résili', '', 2), ('mon', '', 2), ('abon', '', 2), ('chez', '', 2), ('mon', '', 2), ('ancien', '', 2), ('oper', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('comment', '', 2), ('savoir', '', 2), ('si', '', 2), ('le', '', 2), ('chaussur', '', 2), ('de', '', 2), ('mon', '', 2), ('enfant', '', 2), ('sont', '', 2), ('trop', '', 2), ('grand', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('peut', '', 2), ('-', '', 2), ('on', '', 2), ('port', '', 2), ('de', '', 2), ('chaussur', '', 2), ('nik', '', 2), ('san', '', 2), ('chausset', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('l', '', 2), ('’', '', 2), ('utilis', '', 2), ('de', '', 2), ('perch', '', 2), ('télescop', '', 2), (',', '', 2), ('utilis', '', 2), ('not', '', 2), ('pour', '', 2), ('le', '', 2), ('self', '', 2), (',', '', 2), ('est-el', '', 2), ('autoris', '', 2), ('dan', '', 2), ('le', '', 2), ('parc', '', 2), ('à', '', 2), ('them', '', 2), ('de', '', 2), ('disneyland', '', 2), ('paris', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('je', '', 2), ('suis', '', 2), ('handicap', '', 2), ('.', '', 2), ('est', '', 2), ('-ce', '', 2), ('que', '', 2), ('je', '', 2), ('bénéfic', '', 2), (\"d'\", '', 2), ('un', '', 2), ('acces', '', 2), ('spécial', '', 2), ('aux', '', 2), ('attract', '', 2), ('et', '', 2), ('spectacl', '', 2), ('?', '', 2)]\n",
      "Saved model to C:\\Users\\Benco\\Documents\\chatBot_disney\n",
      "Loading from C:\\Users\\Benco\\Documents\\chatBot_disney\n",
      "Entities []\n",
      "Tokens [('puis', '', 2), ('-', '', 2), ('j', '', 2), ('sort', '', 2), (\"d'\", '', 2), ('un', '', 2), ('parc', '', 2), ('disney', '', 2), ('et', '', 2), ('reven', '', 2), ('plus', '', 2), ('tard', '', 2), ('le', '', 2), ('mêm', '', 2), ('jour', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('y', '', 2), ('a', '', 2), ('-t', '', 2), ('-il', '', 2), ('de', '', 2), ('servic', '', 2), ('spécial', '', 2), ('et', '', 2), ('de', '', 2), ('attract', '', 2), ('pour', '', 2), ('le', '', 2), ('beb', '', 2), ('et', '', 2), ('enfant', '', 2), ('en', '', 2), ('bas', '', 2), ('âge', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('pourrai', '', 2), ('-', '', 2), ('j', '', 2), ('utilis', '', 2), ('mon', '', 2), ('mobil', '', 2), ('pour', '', 2), ('du', '', 2), ('partag', '', 2), ('de', '', 2), ('connexion', '', 2), ('(', '', 2), ('permettr', '', 2), ('grâc', '', 2), ('à', '', 2), ('mon', '', 2), ('mobil', '', 2), ('un', '', 2), ('acces', '', 2), ('à', '', 2), ('internet', '', 2), ('à', '', 2), ('un', '', 2), ('ordin', '', 2), (',', '', 2), ('une', '', 2), ('tablet', '', 2), ('ou', '', 2), ('un', '', 2), ('autr', '', 2), ('téléphon', '', 2), (')', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('existe', '', 2), ('-', '', 2), ('t', '', 2), ('-', '', 2), ('il', '', 2), ('un', '', 2), ('servic', '', 2), ('objet', '', 2), ('trouv', '', 2), ('dan', '', 2), ('le', '', 2), ('parc', '', 2), ('disney', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('comment', '', 2), ('me', '', 2), ('rendr', '', 2), ('aux', '', 2), ('parc', '', 2), ('disney', '', 2), ('depuis', '', 2), ('mon', '', 2), ('hôtel', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('où', '', 2), ('chang', '', 2), ('de', '', 2), ('devis', '', 2), ('à', '', 2), ('disneyland', '', 2), ('paris', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('combien', '', 2), ('de', '', 2), ('temp', '', 2), ('durent', '', 2), ('le', '', 2), ('chaussur', '', 2), ('à', '', 2), ('crampon', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('comment', '', 2), ('postul', '', 2), ('pour', '', 2), ('un', '', 2), ('travail', '', 2), ('à', '', 2), ('disneyland', '', 2), ('paris', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('comment', '', 2), ('puis', '', 2), ('-', '', 2), ('j', '', 2), ('me', '', 2), ('procur', '', 2), ('de', '', 2), ('ticket', '', 2), ('fastpassl', '', 2), ('jour', '', 2), ('de', '', 2), ('ma', '', 2), ('visit', '', 2), ('aux', '', 2), ('parc', '', 2), ('et', '', 2), ('diminu', '', 2), ('le', '', 2), ('temp', '', 2), ('d', '', 2), ('’', '', 2), ('attent', '', 2), ('dan', '', 2), ('certain', '', 2), ('attract', '', 2), ('à', '', 2), ('succes', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('quel', '', 2), ('sont', '', 2), ('le', '', 2), ('horair', '', 2), (\"d'\", '', 2), ('ouvertur', '', 2), ('du', '', 2), ('bureau', '', 2), ('pass', '', 2), ('annuel', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('avec', '', 2), ('le', '', 2), ('billet', '', 2), ('privileg', '', 2), (',', '', 2), ('l', '', 2), ('’', '', 2), ('offre', '', 2), ('billet', '', 2), ('amis', '', 2), ('est-el', '', 2), ('amen', '', 2), ('à', '', 2), ('disparaîtr', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('notr', '', 2), ('budget', '', 2), ('est', '', 2), ('serr', '', 2), ('.', '', 2), ('y', '', 2), ('a', '', 2), ('-t', '', 2), ('-il', '', 2), ('de', '', 2), ('restaur', '', 2), ('moin', '', 2), ('cher', '', 2), ('dan', '', 2), ('le', '', 2), ('parc', '', 2), ('disney', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('que', '', 2), ('fair', '', 2), ('si', '', 2), ('mon', '', 2), ('enfant', '', 2), ('se', '', 2), ('perd', '', 2), ('dan', '', 2), ('un', '', 2), ('parc', '', 2), ('disney', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('est-il', '', 2), ('possibl', '', 2), ('de', '', 2), ('recevoir', '', 2), ('un', '', 2), ('pass', '', 2), ('annuel', '', 2), ('direct', '', 2), ('chez', '', 2), ('soi', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('combien', '', 2), ('de', '', 2), ('mois', '', 2), ('sont', '', 2), ('offert', '', 2), ('pour', '', 2), ('le', '', 2), ('parrainag', '', 2), ('de', '', 2), ('3', '', 2), ('filleul', '', 2), ('effectu', '', 2), ('et', '', 2), ('valid', '', 2), ('avant', '', 2), ('le', '', 2), ('28', '', 2), ('mar', '', 2), ('2017', '', 2), ('et', '', 2), ('sur', '', 2), ('quel', '', 2), ('pass', '', 2), ('annuel', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('le', '', 2), ('accompagn', '', 2), (\"d'\", '', 2), ('un', '', 2), ('pass', '', 2), ('annuel', '', 2), ('magic', '', 2), ('plus', '', 2), ('ou', '', 2), ('infinity', '', 2), ('peuvent', '', 2), ('-', '', 2), ('il', '', 2), ('égal', '', 2), ('profit', '', 2), ('de', '', 2), (\"l'\", '', 2), ('acces', '', 2), ('dédi', '', 2), ('à', '', 2), ('l', '', 2), ('’', '', 2), ('entré', '', 2), ('de', '', 2), ('parc', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('pourquoi', '', 2), ('la', '', 2), ('chaussur', '', 2), ('de', '', 2), ('mon', '', 2), ('enfant', '', 2), ('glisse', '', 2), ('-', '', 2), ('t', '', 2), ('-', '', 2), ('el', '', 2), ('au', '', 2), ('niveau', '', 2), ('du', '', 2), ('talon', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('où', '', 2), ('puis', '', 2), ('-', '', 2), ('j', '', 2), ('retir', '', 2), ('de', '', 2), (\"l'\", '', 2), ('argent', '', 2), ('dan', '', 2), ('le', '', 2), ('parc', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('à', '', 2), ('quel', '', 2), ('fréquenc', '', 2), ('dois', '', 2), ('-', '', 2), ('j', '', 2), ('achet', '', 2), ('de', '', 2), ('nouvel', '', 2), ('chaussur', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('j', '', 2), ('’', '', 2), ('ai', '', 2), ('un', '', 2), ('iphon', '', 2), ('.', '', 2), ('vais', '', 2), ('-', '', 2), ('j', '', 2), ('recevoir', '', 2), ('une', '', 2), ('cart', '', 2), ('sim', '', 2), ('au', '', 2), ('format', '', 2), ('adapt', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('comment', '', 2), ('mettr', '', 2), ('une', '', 2), ('chaussur', '', 2), ('à', '', 2), ('crampon', '', 2), ('avec', '', 2), ('un', '', 2), ('col', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('si', '', 2), ('je', '', 2), ('fais', '', 2), ('de', '', 2), ('achat', '', 2), ('dan', '', 2), ('une', '', 2), ('boutiqu', '', 2), ('disney', '', 2), (',', '', 2), ('dois', '', 2), ('-', '', 2), ('j', '', 2), ('le', '', 2), ('port', '', 2), ('tout', '', 2), ('la', '', 2), ('journ', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('où', '', 2), ('trouv', '', 2), ('de', '', 2), ('descript', '', 2), ('et', '', 2), ('photos', '', 2), ('de', '', 2), ('hôtel', '', 2), ('disney', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('est', '', 2), ('-ce', '', 2), ('que', '', 2), ('je', '', 2), ('vais', '', 2), ('recevoir', '', 2), ('une', '', 2), ('offre', '', 2), ('de', '', 2), ('renouvel', '', 2), ('lorsqu', '', 2), ('mon', '', 2), ('pass', '', 2), ('annuel', '', 2), ('arriv', '', 2), ('à', '', 2), ('expir', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('existe', '', 2), ('-', '', 2), ('t', '', 2), ('-', '', 2), ('il', '', 2), ('de', '', 2), ('visit', '', 2), ('guid', '', 2), ('de', '', 2), ('parc', '', 2), ('disney', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('comment', '', 2), ('me', '', 2), ('rendr', '', 2), ('aux', '', 2), ('parc', '', 2), ('disney', '', 2), ('depuis', '', 2), ('mon', '', 2), ('hôtel', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('quel', '', 2), ('hôtel', '', 2), ('sont', '', 2), ('situ', '', 2), ('à', '', 2), ('proxim', '', 2), ('de', '', 2), ('parc', '', 2), ('disney', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('où', '', 2), ('trouv', '', 2), ('de', '', 2), ('inform', '', 2), ('sur', '', 2), ('le', '', 2), ('éven', '', 2), ('de', '', 2), ('saison', '', 2), ('et', '', 2), ('le', '', 2), ('offre', '', 2), ('spécial', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('je', '', 2), ('dispos', '', 2), ('d', '', 2), ('’', '', 2), ('un', '', 2), ('blackberry', '', 2), (',', '', 2), ('devrai', '', 2), ('-', '', 2), ('j', '', 2), ('pai', '', 2), ('l', '', 2), ('’', '', 2), ('option', '', 2), ('blackberry', '', 2), ('pour', '', 2), ('profit', '', 2), ('de', '', 2), ('servic', '', 2), ('internet', '', 2), ('associ', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('quel', '', 2), ('sont', '', 2), ('le', '', 2), ('activ', '', 2), ('possibl', '', 2), ('à', '', 2), ('disneyland', '', 2), ('paris', '', 2), ('pour', '', 2), ('le', '', 2), ('vacanc', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('à', '', 2), ('quel', '', 2), ('heur', '', 2), ('sont', '', 2), (\"l'\", '', 2), ('enregistr', '', 2), ('et', '', 2), ('le', '', 2), ('départ', '', 2), ('dan', '', 2), ('le', '', 2), ('hôtel', '', 2), ('disney', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [(\"qu'\", '', 2), ('est', '', 2), ('-', '', 2), ('c', '', 2), ('que', '', 2), ('le', '', 2), ('fastpass', '', 2), ('disneyland', '', 2), ('paris', '', 2), ('et', '', 2), ('comment', '', 2), ('fonctionne', '', 2), ('-', '', 2), ('t', '', 2), ('-', '', 2), ('il', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('où', '', 2), ('puis', '', 2), ('-', '', 2), ('j', '', 2), ('me', '', 2), ('rendr', '', 2), ('si', '', 2), ('je', '', 2), ('me', '', 2), ('bless', '', 2), ('ou', '', 2), ('si', '', 2), (\"j'\", '', 2), ('ai', '', 2), ('besoin', '', 2), ('de', '', 2), ('soin', '', 2), ('médical', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [(\"qu'\", '', 2), ('est', '', 2), ('-', '', 2), ('c', '', 2), ('que', '', 2), (\"l'\", '', 2), ('express', '', 2), ('check', '', 2), ('-', '', 2), ('out', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [(\"qu'\", '', 2), ('est', '', 2), ('-', '', 2), ('c', '', 2), ('que', '', 2), ('le', '', 2), ('col', '', 2), ('dynamic', '', 2), ('fit', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('quel', '', 2), ('servic', '', 2), ('sont', '', 2), ('disponibl', '', 2), ('pour', '', 2), ('le', '', 2), ('enfant', '', 2), ('et', '', 2), ('beb', '', 2), ('dan', '', 2), ('le', '', 2), ('hôtel', '', 2), ('disney', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('puis', '', 2), ('-', '', 2), ('j', '', 2), ('apport', '', 2), ('de', '', 2), ('la', '', 2), ('nourritur', '', 2), ('dan', '', 2), ('le', '', 2), ('parc', '', 2), ('disney', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('quel', '', 2), ('typ', '', 2), ('de', '', 2), ('restaur', '', 2), ('trouv', '', 2), ('t', '', 2), ('-', '', 2), ('on', '', 2), ('dan', '', 2), ('le', '', 2), ('parc', '', 2), ('disney', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('le', '', 2), ('forf', '', 2), ('à', '', 2), ('2', '', 2), ('€', '', 2), ('est-il', '', 2), ('accessibl', '', 2), ('à', '', 2), ('tous', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('que', '', 2), ('sont', '', 2), ('le', '', 2), ('moment', '', 2), ('de', '', 2), ('mag', '', 2), ('en', '', 2), ('plus', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('quel', '', 2), ('sont', '', 2), ('le', '', 2), ('meilleur', '', 2), ('chaussur', '', 2), ('pour', '', 2), ('le', '', 2), ('running', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('quel', '', 2), ('attract', '', 2), ('seront', '', 2), ('en', '', 2), ('cour', '', 2), ('de', '', 2), ('rénov', '', 2), ('ou', '', 2), ('de', '', 2), ('remis', '', 2), ('en', '', 2), ('état', '', 2), ('au', '', 2), ('cour', '', 2), ('de', '', 2), ('mon', '', 2), ('séjour', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('pourquoi', '', 2), ('le', '', 2), ('chaussur', '', 2), ('de', '', 2), ('mon', '', 2), ('enfant', '', 2), ('grincent', '', 2), ('-', '', 2), ('el', '', 2), ('parfois', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('j', '', 2), ('’', '', 2), ('ai', '', 2), ('bénéfici', '', 2), ('de', '', 2), ('mois', '', 2), ('gratuit', '', 2), ('de', '', 2), ('l', '', 2), ('’', '', 2), ('offre', '', 2), ('de', '', 2), ('parrainag', '', 2), ('et', '', 2), ('je', '', 2), ('souhait', '', 2), ('l', '', 2), ('’', '', 2), ('échang', '', 2), ('contr', '', 2), ('un', '', 2), ('nouveau', '', 2), ('pass', '', 2), ('annuel', '', 2), (',', '', 2), ('quel', '', 2), ('prix', '', 2), ('dois', '', 2), ('-', '', 2), ('j', '', 2), ('pai', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('où', '', 2), ('se', '', 2), ('trouv', '', 2), ('disneyland', '', 2), ('paris', '', 2), ('par', '', 2), ('rapport', '', 2), ('aux', '', 2), ('aéroport', '', 2), ('parisien', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('quel', '', 2), ('est', '', 2), ('le', '', 2), ('meilleur', '', 2), ('moment', '', 2), ('pour', '', 2), ('visit', '', 2), ('disneyland', '', 2), ('paris', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('où', '', 2), ('puis', '', 2), ('-', '', 2), ('j', '', 2), ('me', '', 2), ('rendr', '', 2), ('si', '', 2), ('mon', '', 2), ('enfant', '', 2), ('se', '', 2), ('bless', '', 2), ('ou', '', 2), ('a', '', 2), ('besoin', '', 2), ('de', '', 2), ('soin', '', 2), ('médical', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('comment', '', 2), ('puis', '', 2), ('-', '', 2), ('j', '', 2), ('vérifi', '', 2), ('que', '', 2), ('ma', '', 2), ('souscript', '', 2), ('a', '', 2), ('été', '', 2), ('enregistr', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('où', '', 2), ('puis', '', 2), ('-', '', 2), ('j', '', 2), ('chang', '', 2), ('ou', '', 2), ('nourr', '', 2), ('mon', '', 2), ('beb', '', 2), ('ou', '', 2), ('réchauff', '', 2), ('de', '', 2), ('bib', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('le', '', 2), ('prix', '', 2), ('avec', '', 2), ('un', '', 2), ('pai', '', 2), ('compt', '', 2), ('ou', '', 2), ('mensuel', '', 2), ('est-il', '', 2), ('le', '', 2), ('mêm', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('combien', '', 2), ('dois', '', 2), ('-', '', 2), ('j', '', 2), ('pai', '', 2), ('de', '', 2), ('frais', '', 2), ('de', '', 2), ('résili', '', 2), ('si', '', 2), ('je', '', 2), ('quitt', '', 2), ('mon', '', 2), ('oper', '', 2), ('actuel', '', 2), ('alor', '', 2), ('que', '', 2), ('je', '', 2), ('suis', '', 2), ('encor', '', 2), ('engag', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('je', '', 2), ('souhait', '', 2), ('command', '', 2), ('un', '', 2), ('téléphon', '', 2), ('chez', '', 2), ('fre', '', 2), (',', '', 2), ('comment', '', 2), ('fair', '', 2), ('?', '', 2)]\n",
      "Entities []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens [('comment', '', 2), ('profit', '', 2), ('d', '', 2), ('’', '', 2), ('un', '', 2), ('deuxiem', '', 2), ('(', '', 2), ('ou', '', 2), ('troisiem', '', 2), (',', '', 2), ('ou', '', 2), ('quatriem', '', 2), (')', '', 2), ('`', '', 2), ('`', '', 2), ('forf', '', 2), ('fre', '', 2), (\"''\", '', 2), ('à', '', 2), ('15,99', '', 2), ('€', '', 2), ('par', '', 2), ('mois', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [(\"j'\", '', 2), ('ai', '', 2), ('une', '', 2), ('question', '', 2), ('mais', '', 2), ('je', '', 2), ('ne', '', 2), ('trouv', '', 2), ('pas', '', 2), ('la', '', 2), ('répons', '', 2), ('dan', '', 2), ('cet', '', 2), ('rubriqu', '', 2), (',', '', 2), ('que', '', 2), ('puis', '', 2), ('-', '', 2), ('j', '', 2), ('fair', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('mon', '', 2), ('enfant', '', 2), ('peut', '', 2), ('-', '', 2), ('il', '', 2), ('port', '', 2), ('de', '', 2), ('chaussur', '', 2), ('à', '', 2), ('crampon', '', 2), ('destin', '', 2), ('à', '', 2), (\"d'\", '', 2), ('autr', '', 2), ('sport', '', 2), (',', '', 2), ('comm', '', 2), ('le', '', 2), ('football', '', 2), ('américain', '', 2), ('ou', '', 2), ('le', '', 2), ('baseball', '', 2), (',', '', 2), ('pour', '', 2), ('le', '', 2), ('match', '', 2), ('de', '', 2), ('football', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('je', '', 2), ('possed', '', 2), ('actuel', '', 2), ('un', '', 2), ('passeport', '', 2), ('annuel', '', 2), ('classic', '', 2), (',', '', 2), ('fantasy', '', 2), ('ou', '', 2), ('dream', '', 2), (',', '', 2), ('suis', '', 2), ('-', '', 2), ('j', '', 2), ('oblig', '', 2), ('(', '', 2), ('e', '', 2), (')', '', 2), ('de', '', 2), ('le', '', 2), ('chang', '', 2), ('pour', '', 2), ('un', '', 2), ('nouveau', '', 2), ('pass', '', 2), ('annuel', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [(\"qu'\", '', 2), ('est', '', 2), ('-', '', 2), ('c', '', 2), ('que', '', 2), ('disney', '', 2), ('villag', '', 2), ('et', '', 2), ('que', '', 2), ('peut', '', 2), ('-', '', 2), ('on', '', 2), ('y', '', 2), ('fair', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('le', '', 2), ('réseau', '', 2), ('mobil', '', 2), ('de', '', 2), ('fre', '', 2), ('est-il', '', 2), ('compatibl', '', 2), ('3', '', 2), ('g', '', 2), (',', '', 2), ('3g+', '', 2), ('et', '', 2), ('4', '', 2), ('g', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('où', '', 2), ('puis', '', 2), ('-', '', 2), ('j', '', 2), ('voir', '', 2), ('le', '', 2), ('personnag', '', 2), ('disney', '', 2), ('à', '', 2), ('disneyland', '', 2), ('paris', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('où', '', 2), ('trouv', '', 2), ('de', '', 2), ('inform', '', 2), ('sur', '', 2), ('le', '', 2), ('limit', '', 2), ('de', '', 2), ('taill', '', 2), ('et', '', 2), (\"d'\", '', 2), ('âg', '', 2), ('pour', '', 2), ('le', '', 2), ('attract', '', 2), ('de', '', 2), ('disneyland', '', 2), ('paris', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('comment', '', 2), ('abon', '', 2), ('le', '', 2), ('autr', '', 2), ('membr', '', 2), ('du', '', 2), ('foi', '', 2), ('en', '', 2), ('forf', '', 2), ('mobil', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('où', '', 2), ('puis', '', 2), ('-', '', 2), ('j', '', 2), ('me', '', 2), ('gar', '', 2), ('à', '', 2), ('disneyland', '', 2), ('paris', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('comment', '', 2), ('fêt', '', 2), ('un', '', 2), ('anniversair', '', 2), ('à', '', 2), ('disneyland', '', 2), ('paris', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('je', '', 2), ('suis', '', 2), ('handicap', '', 2), ('.', '', 2), ('quel', '', 2), ('attract', '', 2), ('me', '', 2), ('conviennent', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('l', '', 2), ('’', '', 2), ('offre', '', 2), ('préférentiel', '', 2), ('destin', '', 2), ('aux', '', 2), ('freenaut', '', 2), ('adsl', '', 2), ('n', '', 2), ('’', '', 2), ('est-el', '', 2), ('donc', '', 2), ('valabl', '', 2), ('qu', '', 2), ('’', '', 2), ('une', '', 2), ('fois', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('où', '', 2), ('trouv', '', 2), ('un', '', 2), ('plan', '', 2), ('de', '', 2), ('disneyland', '', 2), ('paris', '', 2), ('et', '', 2), ('de', '', 2), ('parc', '', 2), ('disney', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('quel', '', 2), ('sont', '', 2), ('le', '', 2), ('mesur', '', 2), ('de', '', 2), ('sécur', '', 2), ('mis', '', 2), ('en', '', 2), ('plac', '', 2), ('à', '', 2), ('disneyland', '', 2), ('paris', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('je', '', 2), ('possed', '', 2), ('actuel', '', 2), ('un', '', 2), ('passeport', '', 2), ('annuel', '', 2), ('classic', '', 2), (',', '', 2), ('fantasy', '', 2), ('ou', '', 2), ('dream', '', 2), ('et', '', 2), ('je', '', 2), ('souhait', '', 2), ('l', '', 2), ('’', '', 2), ('échang', '', 2), ('contr', '', 2), ('un', '', 2), ('nouveau', '', 2), ('pass', '', 2), ('annuel', '', 2), (',', '', 2), ('existe', '', 2), ('-', '', 2), ('t', '', 2), ('-', '', 2), ('il', '', 2), ('un', '', 2), ('prix', '', 2), ('au', '', 2), ('prorat', '', 2), ('de', '', 2), ('jour', '', 2), ('rest', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('je', '', 2), ('vais', '', 2), ('prendr', '', 2), ('le', '', 2), ('train', '', 2), ('pour', '', 2), ('me', '', 2), ('rendr', '', 2), ('à', '', 2), ('disneyland', '', 2), ('paris', '', 2), (',', '', 2), ('y', '', 2), ('a', '', 2), ('-t', '', 2), ('-il', '', 2), ('une', '', 2), ('gar', '', 2), ('à', '', 2), ('proxim', '', 2), ('de', '', 2), ('parc', '', 2), ('disney', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('qu', '', 2), (\"'\", '', 2), ('y', '', 2), ('a', '', 2), ('-t', '', 2), ('-il', '', 2), ('à', '', 2), ('fair', '', 2), ('à', '', 2), ('disneyland', '', 2), ('paris', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('quel', '', 2), ('sont', '', 2), ('le', '', 2), ('activ', '', 2), ('possibl', '', 2), ('à', '', 2), ('disneyland', '', 2), ('paris', '', 2), ('pour', '', 2), ('le', '', 2), ('vacanc', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('quel', '', 2), ('sont', '', 2), ('le', '', 2), ('avantag', '', 2), ('du', '', 2), ('pass', '', 2), ('annuel', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('j', '', 2), ('’', '', 2), ('ai', '', 2), ('perdu', '', 2), ('ma', '', 2), ('cart', '', 2), ('sim', '', 2), ('.', '', 2), ('que', '', 2), ('fair', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('puis', '', 2), ('-', '', 2), ('j', '', 2), ('profit', '', 2), ('du', '', 2), ('réseau', '', 2), ('freewif', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('comment', '', 2), ('fair', '', 2), ('pour', '', 2), ('profit', '', 2), ('de', '', 2), ('la', '', 2), ('4', '', 2), ('g', '', 2), ('?', '', 2), ('est', '', 2), ('-ce', '', 2), ('gratuit', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('y', '', 2), ('a', '', 2), ('-t', '', 2), ('-il', '', 2), ('de', '', 2), ('chos', '', 2), ('à', '', 2), ('fair', '', 2), (\"s'\", '', 2), ('il', '', 2), ('pleut', '', 2), ('lor', '', 2), ('de', '', 2), ('mon', '', 2), ('séjour', '', 2), ('à', '', 2), ('disneyland', '', 2), ('paris', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('est-il', '', 2), ('possibl', '', 2), ('d', '', 2), ('’', '', 2), ('achet', '', 2), ('un', '', 2), ('photopass+', '', 2), ('annuel', '', 2), ('pour', '', 2), ('le', '', 2), ('détenteur', '', 2), ('d', '', 2), ('’', '', 2), ('un', '', 2), ('passeport', '', 2), ('annuel', '', 2), ('de', '', 2), ('l', '', 2), ('’', '', 2), ('ancien', '', 2), ('gamm', '', 2), ('en', '', 2), ('cour', '', 2), ('de', '', 2), ('valid', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('le', '', 2), ('jour', '', 2), ('de', '', 2), ('restrict', '', 2), ('s', '', 2), ('’', '', 2), ('appliquent', '', 2), ('-', '', 2), ('t', '', 2), ('-', '', 2), ('il', '', 2), ('si', '', 2), ('l', '', 2), ('’', '', 2), ('on', '', 2), ('séjourn', '', 2), ('dan', '', 2), ('un', '', 2), ('hôtel', '', 2), ('disney', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('avec', '', 2), ('un', '', 2), ('pass', '', 2), ('annuel', '', 2), ('infinity', '', 2), (',', '', 2), ('puis', '', 2), ('-', '', 2), ('j', '', 2), ('fair', '', 2), ('bénéfici', '', 2), ('de', '', 2), (\"l'\", '', 2), ('espac', '', 2), ('privilégi', '', 2), ('pour', '', 2), ('la', '', 2), ('parad', '', 2), ('et', '', 2), ('le', '', 2), ('show', '', 2), ('disney', '', 2), ('illumin', '', 2), ('à', '', 2), ('me', '', 2), ('invit', '', 2), ('billet', '', 2), ('privileg', '', 2), (',', '', 2), ('billet', '', 2), ('amis', '', 2), (',', '', 2), ('autr', '', 2), ('détenteur', '', 2), ('de', '', 2), ('pass', '', 2), ('annuel', '', 2), ('ou', '', 2), ('autr', '', 2), ('ticket', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('je', '', 2), ('n', '', 2), ('’', '', 2), ('ai', '', 2), ('reçu', '', 2), ('ni', '', 2), ('mail', '', 2), ('de', '', 2), ('confirm', '', 2), ('ni', '', 2), ('identifi', '', 2), ('pour', '', 2), ('me', '', 2), ('connect', '', 2), ('à', '', 2), ('mon', '', 2), ('espac', '', 2), ('abon', '', 2), ('.', '', 2), ('que', '', 2), ('dois', '', 2), ('-', '', 2), ('j', '', 2), ('fair', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('puis', '', 2), ('-', '', 2), ('j', '', 2), ('aller', '', 2), ('dan', '', 2), ('le', '', 2), ('parc', '', 2), ('et', '', 2), ('hôtel', '', 2), ('disney', '', 2), ('avec', '', 2), ('mon', '', 2), ('chien', '', 2), ('ou', '', 2), ('mon', '', 2), ('chat', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('puis', '', 2), ('-', '', 2), ('j', '', 2), ('me', '', 2), ('rendr', '', 2), ('à', '', 2), ('disneyland', '', 2), ('paris', '', 2), ('en', '', 2), ('transport', '', 2), ('en', '', 2), ('commun', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('lor', '', 2), ('de', '', 2), ('mon', '', 2), ('inscript', '', 2), (',', '', 2), ('j', '', 2), ('’', '', 2), ('ai', '', 2), ('oubli', '', 2), ('de', '', 2), ('chois', '', 2), ('la', '', 2), ('portabl', '', 2), ('de', '', 2), ('mon', '', 2), ('numéro', '', 2), ('.', '', 2), ('puis', '', 2), ('-', '', 2), ('j', '', 2), ('l', '', 2), ('’', '', 2), ('obten', '', 2), ('final', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('le', '', 2), ('prix', '', 2), ('du', '', 2), ('parking', '', 2), ('est-il', '', 2), ('inclus', '', 2), ('dan', '', 2), ('le', '', 2), ('billet', '', 2), (\"d'\", '', 2), ('entr', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('la', '', 2), ('marqu', '', 2), ('nik', '', 2), ('propose', '', 2), ('-', '', 2), ('t', '', 2), ('-', '', 2), ('el', '', 2), ('de', '', 2), ('chaussur', '', 2), ('san', '', 2), ('lacet', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('quel', '', 2), ('sont', '', 2), ('le', '', 2), ('coordon', '', 2), ('de', '', 2), ('disneyland', '', 2), ('paris', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('quel', '', 2), ('sont', '', 2), ('le', '', 2), ('meilleur', '', 2), ('chaussur', '', 2), ('pour', '', 2), (\"l'\", '', 2), ('écol', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('y', '', 2), ('a', '', 2), ('-t', '', 2), ('-il', '', 2), ('un', '', 2), ('cod', '', 2), ('vestimentair', '', 2), ('à', '', 2), ('disneyland', '', 2), ('paris', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('est', '', 2), ('-ce', '', 2), ('possibl', '', 2), ('de', '', 2), ('prendr', '', 2), ('un', '', 2), ('rep', '', 2), ('avec', '', 2), ('de', '', 2), ('personnag', '', 2), ('disney', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('existe', '', 2), ('-', '', 2), ('t', '', 2), ('-', '', 2), ('il', '', 2), ('de', '', 2), ('visit', '', 2), ('guid', '', 2), ('de', '', 2), ('parc', '', 2), ('disney', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('puis', '', 2), ('-', '', 2), ('j', '', 2), ('fum', '', 2), ('dan', '', 2), ('le', '', 2), ('parc', '', 2), ('disney', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('mon', '', 2), ('téléphon', '', 2), ('est', '', 2), ('verrouill', '', 2), ('(', '', 2), ('`', '', 2), ('`', '', 2), ('simlock', '', 2), (\"''\", '', 2), (')', '', 2), ('chez', '', 2), ('mon', '', 2), ('oper', '', 2), ('actuel', '', 2), ('.', '', 2), ('que', '', 2), ('dois', '', 2), ('-', '', 2), ('j', '', 2), ('fair', '', 2), ('avant', '', 2), ('de', '', 2), ('m', '', 2), ('’', '', 2), ('abon', '', 2), ('chez', '', 2), ('fre', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('y', '', 2), ('a', '', 2), ('-t', '', 2), ('-il', '', 2), ('de', '', 2), ('pousset', '', 2), ('dan', '', 2), ('le', '', 2), ('parc', '', 2), ('disney', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('que', '', 2), ('dois', '', 2), ('-', '', 2), ('j', '', 2), ('fair', '', 2), ('en', '', 2), ('cas', '', 2), ('de', '', 2), ('pert', '', 2), ('ou', '', 2), ('de', '', 2), ('vol', '', 2), ('de', '', 2), ('mon', '', 2), ('pass', '', 2), ('annuel', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('que', '', 2), ('comprend', '', 2), ('la', '', 2), ('premi', '', 2), ('factur', '', 2), ('mobil', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('quel', '', 2), ('sont', '', 2), ('le', '', 2), ('heur', '', 2), (\"d'\", '', 2), ('ouvertur', '', 2), ('de', '', 2), ('parc', '', 2), ('disney', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('quel', '', 2), ('attract', '', 2), ('conviennent', '', 2), ('à', '', 2), ('mon', '', 2), ('enfant', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('si', '', 2), ('je', '', 2), ('suis', '', 2), ('abon', '', 2), ('freebox', '', 2), (',', '', 2), ('puis', '', 2), ('-', '', 2), ('j', '', 2), ('bénéfici', '', 2), ('d', '', 2), ('’', '', 2), ('un', '', 2), ('`', '', 2), ('`', '', 2), ('forf', '', 2), ('fre', '', 2), (\"''\", '', 2), ('à', '', 2), ('15,99', '', 2), ('€', '', 2), ('par', '', 2), ('mois', '', 2), ('et', '', 2), ('souscrir', '', 2), ('auss', '', 2), ('le', '', 2), ('`', '', 2), ('`', '', 2), ('forf', '', 2), ('2', '', 2), ('€', '', 2), (\"''\", '', 2), ('factur', '', 2), ('à', '', 2), ('0', '', 2), ('€', '', 2), ('par', '', 2), ('mois', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('quel', '', 2), ('est', '', 2), ('le', '', 2), ('coût', '', 2), ('de', '', 2), ('la', '', 2), ('cart', '', 2), ('sim', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('y', '', 2), ('a', '', 2), ('-t', '', 2), ('-il', '', 2), ('un', '', 2), ('acces', '', 2), ('wif', '', 2), ('à', '', 2), ('disneyland', '', 2), ('paris', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('comment', '', 2), ('le', '', 2), ('fastpass', '', 2), ('disneyland', '', 2), ('paris', '', 2), ('peut', '', 2), ('-', '', 2), ('il', '', 2), (\"m'\", '', 2), ('évit', '', 2), ('de', '', 2), ('fair', '', 2), ('la', '', 2), ('queu', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('quel', '', 2), ('est', '', 2), ('le', '', 2), ('meilleur', '', 2), ('moyen', '', 2), ('de', '', 2), ('se', '', 2), ('déplac', '', 2), ('au', '', 2), ('sein', '', 2), ('de', '', 2), ('disneyland', '', 2), ('paris', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('quel', '', 2), ('est', '', 2), ('le', '', 2), ('meilleur', '', 2), ('moyen', '', 2), ('de', '', 2), ('se', '', 2), ('déplac', '', 2), ('au', '', 2), ('sein', '', 2), ('de', '', 2), ('disneyland', '', 2), ('paris', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('j', '', 2), ('’', '', 2), ('ai', '', 2), ('reçu', '', 2), ('l', '', 2), ('’', '', 2), ('email', '', 2), ('de', '', 2), ('confirm', '', 2), ('de', '', 2), ('souscript', '', 2), ('.', '', 2), ('quand', '', 2), ('vais', '', 2), ('-', '', 2), ('j', '', 2), ('recevoir', '', 2), ('ma', '', 2), ('cart', '', 2), ('sim', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('pourquoi', '', 2), ('la', '', 2), ('soupless', '', 2), ('est-el', '', 2), ('import', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('comment', '', 2), ('déclar', '', 2), ('un', '', 2), ('chang', '', 2), (\"d'\", '', 2), ('adress', '', 2), ('ou', '', 2), ('autr', '', 2), ('situat', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('lor', '', 2), ('de', '', 2), ('mon', '', 2), ('inscript', '', 2), ('chez', '', 2), ('fre', '', 2), (',', '', 2), ('j', '', 2), ('’', '', 2), ('ai', '', 2), ('demand', '', 2), ('à', '', 2), ('conserv', '', 2), ('mon', '', 2), ('numéro', '', 2), ('de', '', 2), ('mobil', '', 2), ('actuel', '', 2), ('(', '', 2), ('portabl', '', 2), (')', '', 2), (',', '', 2), ('dois', '', 2), ('-', '', 2), ('j', '', 2), ('résili', '', 2), ('mon', '', 2), ('abon', '', 2), ('chez', '', 2), ('mon', '', 2), ('ancien', '', 2), ('oper', '', 2), ('?', '', 2)]\n",
      "Entities []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens [('comment', '', 2), ('savoir', '', 2), ('si', '', 2), ('le', '', 2), ('chaussur', '', 2), ('de', '', 2), ('mon', '', 2), ('enfant', '', 2), ('sont', '', 2), ('trop', '', 2), ('grand', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('peut', '', 2), ('-', '', 2), ('on', '', 2), ('port', '', 2), ('de', '', 2), ('chaussur', '', 2), ('nik', '', 2), ('san', '', 2), ('chausset', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('l', '', 2), ('’', '', 2), ('utilis', '', 2), ('de', '', 2), ('perch', '', 2), ('télescop', '', 2), (',', '', 2), ('utilis', '', 2), ('not', '', 2), ('pour', '', 2), ('le', '', 2), ('self', '', 2), (',', '', 2), ('est-el', '', 2), ('autoris', '', 2), ('dan', '', 2), ('le', '', 2), ('parc', '', 2), ('à', '', 2), ('them', '', 2), ('de', '', 2), ('disneyland', '', 2), ('paris', '', 2), ('?', '', 2)]\n",
      "Entities []\n",
      "Tokens [('je', '', 2), ('suis', '', 2), ('handicap', '', 2), ('.', '', 2), ('est', '', 2), ('-ce', '', 2), ('que', '', 2), ('je', '', 2), ('bénéfic', '', 2), (\"d'\", '', 2), ('un', '', 2), ('acces', '', 2), ('spécial', '', 2), ('aux', '', 2), ('attract', '', 2), ('et', '', 2), ('spectacl', '', 2), ('?', '', 2)]\n",
      "Entities in 'et on achet le pain ou ?'\n",
      "Loading from C:\\Users\\Benco\\Documents\\chatBot_disney\n"
     ]
    }
   ],
   "source": [
    "main(model = \"C:/Users/Benco/Anaconda3/Lib/site-packages/fr_core_news_sm/fr_core_news_sm-2.2.5\" , output_dir = output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benco\\Anaconda3\\lib\\runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.32501200593594537"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1 = nlp(train[\"lemmas_quest\"].iloc[80])\n",
    "doc2 = nlp(train[\"lemmas_quest\"].iloc[98])\n",
    "doc1.similarity(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = nltk.corpus.stopwords.words('french')\n",
    "sw += ['être', 'avoir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[train.target == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(lowercase=True, stop_words = sw,\n",
    "                            ngram_range=(1, 1),\n",
    "                            min_df = 3,\n",
    "                            use_idf=True, smooth_idf=True, # idf lissé\n",
    "                            sublinear_tf=False, norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectorized_tfidf = vectorizer.fit_transform(X_train[\"stem_quest\"])# compléter ici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acces</th>\n",
       "      <th>annuel</th>\n",
       "      <th>attract</th>\n",
       "      <th>beb</th>\n",
       "      <th>billet</th>\n",
       "      <th>chang</th>\n",
       "      <th>dan</th>\n",
       "      <th>disney</th>\n",
       "      <th>disneyland</th>\n",
       "      <th>dois</th>\n",
       "      <th>...</th>\n",
       "      <th>plus</th>\n",
       "      <th>possibl</th>\n",
       "      <th>prix</th>\n",
       "      <th>puis</th>\n",
       "      <th>rendr</th>\n",
       "      <th>servic</th>\n",
       "      <th>si</th>\n",
       "      <th>spécial</th>\n",
       "      <th>trouv</th>\n",
       "      <th>visit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.488838</td>\n",
       "      <td>0.408051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.626945</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   acces  annuel  attract  beb  billet  chang       dan    disney  disneyland  \\\n",
       "0    0.0     0.0      0.0  0.0     0.0    0.0  0.488838  0.408051         0.0   \n",
       "\n",
       "   dois  ...  plus  possibl  prix  puis  rendr  servic   si  spécial  \\\n",
       "0   0.0  ...   0.0      0.0   0.0   0.0    0.0     0.0  0.0      0.0   \n",
       "\n",
       "      trouv  visit  \n",
       "0  0.626945    0.0  \n",
       "\n",
       "[1 rows x 33 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = [stem_text(train[\"question\"][69])]\n",
    "query_vector = vectorizer.transform(query)\n",
    "pd.DataFrame(query_vector.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.57364585,\n",
       "       0.70033383, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.36763093, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.70741969, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.52063869, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.31382392, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.40483297, 0.        , 0.        , 0.2996493 , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_corpus_sim = np.squeeze(cosine_similarity(X_train_vectorized_tfidf, query_vector)) ## on enlève leur format qui n'est pas bon --> vecteur\n",
    "query_corpus_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 53, 52, 50, 49, 48, 47, 54, 46, 44, 43, 42, 41, 39, 38, 45, 74,\n",
       "       55, 57, 73, 72, 71, 70, 69, 67, 56, 65, 63, 62, 61, 60, 59, 58, 64,\n",
       "       36, 37, 34,  2,  5,  6,  7,  8,  9, 10, 11, 14, 15, 16, 35, 18, 19,\n",
       "       20, 17, 30, 33, 32, 31, 29, 28, 27, 75, 26, 25, 23, 22,  4, 21, 24,\n",
       "       12,  3, 13, 51, 68, 66,  1, 40], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indice = np.argsort(query_corpus_sim) ## ordre croissant\n",
    "indice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'je possed actuel un passeport annuel classic , fantasy ou dream , suis-j oblig ( e ) de le chang pour un nouveau pass annuel ?'"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"stem_quest\"][indice[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(query_corpus_sim) > 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self , data , stop_words , seuil):\n",
    "        self.data = data\n",
    "        self.stop_words = stop_words\n",
    "        self.stop_words += [\"être\" , \"avoir\" , \"voir\" , \"choisir\" , \"quel\" , \"comment\" , \"?\"]\n",
    "        self.seuil = seuil\n",
    "        \n",
    "    def classification(self , query):\n",
    "        vectorizer = TfidfVectorizer(lowercase=True, stop_words = self.stop_words,\n",
    "                            ngram_range=(1, 2),\n",
    "                            use_idf=True, smooth_idf=True, # idf lissé\n",
    "                            sublinear_tf=False, norm='l2')\n",
    "        X_train_vectorized_tfidf = vectorizer.fit_transform(self.data[\"stem_quest\"])\n",
    "        query = [stem_text(query)]\n",
    "        query_vector = vectorizer.transform(query)\n",
    "        query_corpus_sim = np.squeeze(cosine_similarity(X_train_vectorized_tfidf, query_vector))\n",
    "        nb_non_zeros = np.count_nonzero(query_corpus_sim)\n",
    "        \n",
    "        if (nb_non_zeros >= self.seuil):\n",
    "            return 1\n",
    "            #return {\"classif\" : 1 , \"doc_most_similar\" : np.argsort(query_corpus_sim)[-nb_non_zeros:]}\n",
    "        else:\n",
    "            return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = Agent(X_train , sw , 10)\n",
    "agent.classification(train[\"question\"][105])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09210526315789473"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpt = 0\n",
    "for i in range(76):\n",
    "    if(agent.classification(train[\"question\"][i]) == 0):\n",
    "        cpt += 1\n",
    "cpt/(76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
