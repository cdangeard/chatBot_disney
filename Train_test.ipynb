{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import spacy\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "import numpy as np\n",
    "import nltk\n",
    "import random\n",
    "from langdetect import detect\n",
    "from pathlib import Path\n",
    "from textblob import TextBlob\n",
    "from spacy.util import minibatch, compounding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('french')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatise_text(text):\n",
    "    tweet_nlp = nlp(text)\n",
    "    l = [token.lemma_ for token in tweet_nlp ]\n",
    "    return (\" \".join(l)).replace(\" \\n\",\"\")\n",
    "\n",
    "def stem_text(text):\n",
    "    words = word_tokenize(text)\n",
    "    l = [stemmer.stem(token) for token in words]\n",
    "    return \" \".join(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"C:/Users/Benco/Anaconda3/Lib/site-packages/fr_core_news_sm/fr_core_news_sm-2.2.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train_data.csv\")\n",
    "train = train[[\"question\" , \"reponse\"]]\n",
    "train[\"lemmas_rep\"] = train[\"reponse\"].apply(lemmatise_text)\n",
    "train[\"lemmas_quest\"] = train[\"question\"].apply(lemmatise_text)\n",
    "train[\"stem_rep\"] = train[\"reponse\"].apply(stem_text)\n",
    "train[\"stem_quest\"] = train[\"question\"].apply(stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"training_data.csv\" , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_random = (pd.read_csv(\"training_data.csv\")).sample(120)\n",
    "train_random.to_csv(\"training_data_random.csv\" , index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exécute à partir d'ici : il faut q'on ait le même fichier quand même"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_random = pd.read_csv(\"training_data_random.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "indice_test = [i for i in range(144) if(i not in train_random.index)] \n",
    "X_test = (train.iloc[indice_test , :][[\"question\" , \"reponse\"]])\n",
    "X_test[\"target\"] = 1\n",
    "X_test.columns = [\"comb_quest\" , \"comb_rep\" , \"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = nltk.corpus.stopwords.words('french')\n",
    "sw += ['être', 'avoir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(lowercase=True, stop_words = sw,\n",
    "                            ngram_range=(1, 1),\n",
    "                             min_df = 1,\n",
    "                            use_idf=True, smooth_idf=True, # idf lissé\n",
    "                            sublinear_tf=False, norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectorized_tfidf = vectorizer.fit_transform(pd.concat([train_random[\"lemmas_quest\"].apply(stem_text) , train_random[\"lemmas_rep\"].apply(stem_text)]))# compléter ici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>024</th>\n",
       "      <th>03</th>\n",
       "      <th>078</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>10h</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>émettr</th>\n",
       "      <th>équip</th>\n",
       "      <th>établ</th>\n",
       "      <th>étap</th>\n",
       "      <th>état</th>\n",
       "      <th>étendr</th>\n",
       "      <th>étroit</th>\n",
       "      <th>évad</th>\n",
       "      <th>éven</th>\n",
       "      <th>évit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 1339 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000   01   02  024   03  078   10  100  10h   11  ...  émettr  équip  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0    0.0   \n",
       "\n",
       "   établ  étap  état  étendr  étroit  évad  éven  évit  \n",
       "0    0.0   0.0   0.0     0.0     0.0   0.0   0.0   0.0  \n",
       "\n",
       "[1 rows x 1339 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = [stem_text(\"Quels sont les tarifs pour une réservation à l'hôtel ?\")]\n",
    "query_vector = vectorizer.transform(query)\n",
    "pd.DataFrame(query_vector.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5597115400373813"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_corpus_sim = np.squeeze(cosine_similarity(X_train_vectorized_tfidf, query_vector)) ## on enlève leur format qui n'est pas bon --> vecteur\n",
    "np.max(query_corpus_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_best_doc = np.argsort(query_corpus_sim)[-1]\n",
    "id_best_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Il existe un hôtel Disney pour toutes les bourses à Disneyland Paris. Vous pouvez découvrir les tarifs via notre service de réservation en ligne pratique et sécurisé.Trouvez votre hôtel de rêve DisneyRéservez votre séjour dès aujourd'hui !\""
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " ## ordre croissant\n",
    "if(id_best_doc >= 120):\n",
    "    doc = train_random[\"reponse\"][id_best_doc-120]\n",
    "else:\n",
    "    doc = train_random[\"reponse\"][id_best_doc]\n",
    "doc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comb_quest</th>\n",
       "      <th>comb_rep</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>puis - je réserv le mêm forf en lign et par té...</td>\n",
       "      <td>malheur , non . notr servic de réserv en lign ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>comment postul pour un travail à disneyland pa...</td>\n",
       "      <td>disneyland paris être toujour à le recherch de...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>qu ' y avoir t il à fair à disneyland paris ?</td>\n",
       "      <td>disneyland paris être un destin de vacanc magi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>puis - je apport de le nourritur dan le parc d...</td>\n",
       "      <td>le rep collect qui nécessit un logist particul...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>pourquoi un messag de erreur se affich - t - i...</td>\n",
       "      <td>il pouvoir y avoir plusieur raison à cel : le ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>que signifi télécharg et comment télécharg un ...</td>\n",
       "      <td>télécharg être un procédur qui vous permettr d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>comment trouv rapid un inform sur un sujet par...</td>\n",
       "      <td>consult le plan de sit . il offrir un vu de en...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>que être ce que le fastp disneyland paris et c...</td>\n",
       "      <td>le disneyland paris fastpass être un servic gr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>y avoir t il un acces wif à disneyland paris ?</td>\n",
       "      <td>oui ! le wif gratuit être disponibl dan certai...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>être ce que je aller recevoir un offre de reno...</td>\n",
       "      <td>lorsqu votr pass annuel arriv à expir , vous r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>que doi - je fair en cas de pert ou de vol de ...</td>\n",
       "      <td>le adhérent devoir inform disneyland paris de ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>puis - je aller dan le parc et hôtel disney av...</td>\n",
       "      <td>non . pour un raison de sant et de sécur , le ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>que être ce que disney villag et comment se y ...</td>\n",
       "      <td>disney villag être idéal situ entre le parc di...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>le restaur de disneyland paris propos - il un ...</td>\n",
       "      <td>oui . vous trouv un menu pour enfant dan le pl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>je être handicap . quel attract me conven ?</td>\n",
       "      <td>disneyland paris être dot de attract conven à ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>quel attract conven à mon enfant ?</td>\n",
       "      <td>disneyland paris être dot de attract conven au...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>que être le moment de mag en plus ?</td>\n",
       "      <td>en séjourn dan l ’ un un hôtel disney ou si vo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>je possed actuel un passeport annuel classic ,...</td>\n",
       "      <td>non , le passeport annuel être valid jusqu ’ à...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>le restaur disney répondent - il à mon besoin ...</td>\n",
       "      <td>le plupart de notr restaur avec servic à tabl ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>où se trouv le centr accueil animal ?</td>\n",
       "      <td>le centr accueil animal se trouv à proxim de p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>je souffr de intoler alimentair , où puis - je...</td>\n",
       "      <td>pas de inquiétud . le restaur disney être heur...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>est - il possibl d ’ achet un photopass+ annue...</td>\n",
       "      <td>oui , selon le condit tarifair en vigueur au m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>y avoir t il un pousset dan le parc disney ?</td>\n",
       "      <td>oui . il être possibl de lou un pousset au poi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>quel film être actuel projet au cinem gaumont ?</td>\n",
       "      <td>rend - vous sur le sit web de cinem gaumont po...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comb_quest  \\\n",
       "120  puis - je réserv le mêm forf en lign et par té...   \n",
       "121  comment postul pour un travail à disneyland pa...   \n",
       "122      qu ' y avoir t il à fair à disneyland paris ?   \n",
       "123  puis - je apport de le nourritur dan le parc d...   \n",
       "124  pourquoi un messag de erreur se affich - t - i...   \n",
       "125  que signifi télécharg et comment télécharg un ...   \n",
       "126  comment trouv rapid un inform sur un sujet par...   \n",
       "127  que être ce que le fastp disneyland paris et c...   \n",
       "128     y avoir t il un acces wif à disneyland paris ?   \n",
       "129  être ce que je aller recevoir un offre de reno...   \n",
       "130  que doi - je fair en cas de pert ou de vol de ...   \n",
       "131  puis - je aller dan le parc et hôtel disney av...   \n",
       "132  que être ce que disney villag et comment se y ...   \n",
       "133  le restaur de disneyland paris propos - il un ...   \n",
       "134        je être handicap . quel attract me conven ?   \n",
       "135                 quel attract conven à mon enfant ?   \n",
       "136                que être le moment de mag en plus ?   \n",
       "137  je possed actuel un passeport annuel classic ,...   \n",
       "138  le restaur disney répondent - il à mon besoin ...   \n",
       "139              où se trouv le centr accueil animal ?   \n",
       "140  je souffr de intoler alimentair , où puis - je...   \n",
       "141  est - il possibl d ’ achet un photopass+ annue...   \n",
       "142       y avoir t il un pousset dan le parc disney ?   \n",
       "143    quel film être actuel projet au cinem gaumont ?   \n",
       "\n",
       "                                              comb_rep  target  \n",
       "120  malheur , non . notr servic de réserv en lign ...       1  \n",
       "121  disneyland paris être toujour à le recherch de...       1  \n",
       "122  disneyland paris être un destin de vacanc magi...       1  \n",
       "123  le rep collect qui nécessit un logist particul...       1  \n",
       "124  il pouvoir y avoir plusieur raison à cel : le ...       1  \n",
       "125  télécharg être un procédur qui vous permettr d...       1  \n",
       "126  consult le plan de sit . il offrir un vu de en...       1  \n",
       "127  le disneyland paris fastpass être un servic gr...       1  \n",
       "128  oui ! le wif gratuit être disponibl dan certai...       1  \n",
       "129  lorsqu votr pass annuel arriv à expir , vous r...       1  \n",
       "130  le adhérent devoir inform disneyland paris de ...       1  \n",
       "131  non . pour un raison de sant et de sécur , le ...       1  \n",
       "132  disney villag être idéal situ entre le parc di...       1  \n",
       "133  oui . vous trouv un menu pour enfant dan le pl...       1  \n",
       "134  disneyland paris être dot de attract conven à ...       1  \n",
       "135  disneyland paris être dot de attract conven au...       1  \n",
       "136  en séjourn dan l ’ un un hôtel disney ou si vo...       1  \n",
       "137  non , le passeport annuel être valid jusqu ’ à...       1  \n",
       "138  le plupart de notr restaur avec servic à tabl ...       1  \n",
       "139  le centr accueil animal se trouv à proxim de p...       1  \n",
       "140  pas de inquiétud . le restaur disney être heur...       1  \n",
       "141  oui , selon le condit tarifair en vigueur au m...       1  \n",
       "142  oui . il être possibl de lou un pousset au poi...       1  \n",
       "143  rend - vous sur le sit web de cinem gaumont po...       1  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = requests.get(\"https://www.nike.com/fr/fr_fr/c/kids/how-to-buy-kids-shoes-faq\").text\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "classe_texte_nike = \"nike-cq-subtitle-line-1 nike-cq-title-line nike-cq-line1 nsg-text--dark-grey nike-cq-font22px nike-cq-spacing08px nsg-font-family--platform\"\n",
    "questions_nike = [t.text for t in soup.find_all(\"span\" , {\"class\" : classe_texte_nike})]\n",
    "reponses_nike = [t.find(\"p\").text.replace(\"\\xa0\" , \"\").replace(\"\\n\" , \"\").replace(\"  \",\"\") for t in soup.find_all(\"div\" , {\"class\" : \"nike-cq-text-component nike-cq-misc-copy-block-text-resource\"})]\n",
    "questions_nike = (pd.Series(questions_nike))\n",
    "reponses_nike = (pd.Series(reponses_nike))\n",
    "df = pd.concat([questions_nike , reponses_nike] , axis = 1)\n",
    "df[\"target\"] = 0\n",
    "df.columns = [\"comb_quest\" , \"comb_rep\" , \"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = requests.get(\"https://mobile.free.fr/assistance/163.html\").text\n",
    "soup = BeautifulSoup(html, 'lxml')  \n",
    "lq = pd.Series([t.text.replace(\"\\xa0\" , \"\") for t in soup.select(\"li.clicMe > strong\")])\n",
    "lr =[t.text.replace(\"\\xa0\" , \"\").replace(\"\\n\",\"\").replace(\"\\t\",\"\") for t in soup.find_all(\"li\" , {\"class\" : \"hideMe\"})]\n",
    "lr = (pd.Series(lr[:22]))\n",
    "df_bis = pd.concat([lq, lr], axis=1)\n",
    "df_bis[\"target\"] = 0\n",
    "df_bis.columns = [\"comb_quest\" , \"comb_rep\" , \"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.append(df_bis)\n",
    "df.index = list(range(len(df)))\n",
    "X_test = X_test.append(df)\n",
    "X_test.index = list(range(len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = X_test[[\"comb_quest\" , \"comb_rep\"]].apply(lambda textes : [stem_text(lemmatise_text(txt)) for txt in textes])\n",
    "D[\"target\"] = X_test[\"target\"]\n",
    "X_test = D #je sais que c'est laid !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94        35\n",
      "           1       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.93        59\n",
      "   macro avg       0.94      0.92      0.93        59\n",
      "weighted avg       0.93      0.93      0.93        59\n",
      "\n"
     ]
    }
   ],
   "source": [
    "liste_classif = []\n",
    "\n",
    "for quest in X_test[\"comb_quest\"].to_list():\n",
    "    query_vector = vectorizer.transform([quest])\n",
    "    query_corpus_sim = np.squeeze(cosine_similarity(X_train_vectorized_tfidf, query_vector))\n",
    "    seuil = np.max(query_corpus_sim)\n",
    "    if(seuil > 0.5):\n",
    "        liste_classif.append(1)\n",
    "    else:\n",
    "        liste_classif.append(0)\n",
    "\n",
    "res =  classification_report(X_test[\"target\"], liste_classif)    \n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function str.isnumeric()>"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
